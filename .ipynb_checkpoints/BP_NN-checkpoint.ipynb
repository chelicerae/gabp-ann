{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  class\n",
       "0           5.9          3.0           5.1          1.8      2\n",
       "1           5.6          3.0           4.5          1.5      1\n",
       "2           5.0          3.3           1.4          0.2      0\n",
       "3           6.0          2.2           4.0          1.0      1\n",
       "4           5.8          2.7           3.9          1.2      1\n",
       "5           5.2          3.5           1.5          0.2      0\n",
       "6           5.7          2.8           4.1          1.3      1\n",
       "7           5.0          3.4           1.5          0.2      0\n",
       "8           5.6          2.8           4.9          2.0      2\n",
       "9           5.1          3.8           1.5          0.3      0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-99.80341536 -64.52404744  42.77614549 -76.405061   -72.08232071\n",
      "  14.85601168 -53.68871622  36.09791257 -22.96207116  71.75095558]\n"
     ]
    }
   ],
   "source": [
    "# No bias results 50 000 iterations (-2, 2)\n",
    "\n",
    "# all_weights = np.array([ 0.82850905,  0.40072448, -1.16062222,  0.24129967, -0.00901011,\n",
    "#        -0.55042084,  0.17620743, -0.35640638,  0.28189825, -0.40337483,\n",
    "#        -0.53330681,  0.1720898 ,  1.99998587, -0.0237903 , -1.99372395,\n",
    "#        -1.53997806,  1.31316753, -1.85079916,  1.53083946,  1.20376128,\n",
    "#         2.        , -1.03966506, -1.78537761, -0.57303334, -0.83020559,\n",
    "#         1.2181045 , -0.95560658,  0.32555322, -0.01306465, -0.58740851,\n",
    "#        -0.30109983,  2.        ,  1.7863003 ,  1.87352263, -1.2398616 ,\n",
    "#        -1.35349408,  0.21784511,  2.        , -1.14411966, -0.96291608,\n",
    "#         1.15340453, -0.12331424, -0.68801667,  1.76125887, -1.96991071,\n",
    "#         0.88347918,  0.65414193, -0.13644339,  1.44238258,  1.31562074,\n",
    "#        -0.95010176, -0.08231172, -0.42752867,  1.66501362,  0.62532375,\n",
    "#         1.99714638,  0.73385111, -1.89800158, -0.01269442,  2.        ,\n",
    "#        -0.34806914, -1.06161126,  0.13609927, -1.90406267,  1.64843287,\n",
    "#        -1.89691344,  1.50997576,  1.82210462, -1.48688357, -2.        ])\n",
    "\n",
    "# Bias results 1000 iterations (-100, 100)\n",
    "\n",
    "# all_weights = np.array([-55.99912628,  -2.94074698,  48.62230211,  27.70564858,\n",
    "#        -14.72015624,  -9.42324088, -43.03292206, -18.40727773,\n",
    "#        -43.64839552, -58.04569456, -50.20950896, -85.52187718,\n",
    "#         70.56984522,   5.20257721,  -0.26611847,  83.19208242,\n",
    "#        -72.17945228,  49.45460294,  -2.2190893 ,   4.7459282 ,\n",
    "#        -83.69299758,  58.1335316 , -15.73228806, -34.88828344,\n",
    "#         78.57904655,  68.61037977,  13.15403183,  89.08639842,\n",
    "#         36.90008999, -43.38496429,  93.1164013 ,  10.73194315,\n",
    "#         93.14897671, -50.62290616,   8.02729018,  96.21904633,\n",
    "#         17.4439362 ,  25.44069502,  68.22808982,  -7.54487909,\n",
    "#        -99.80341536, -64.52404744,  42.77614549, -76.405061  ,\n",
    "#        -72.08232071,  14.85601168, -53.68871622,  36.09791257,\n",
    "#        -22.96207116,  71.75095558,  84.62201604, -66.19849963,\n",
    "#        -89.07164706,  65.08517806, -42.65904316,  61.44426617,\n",
    "#         28.48123545, -11.79782272,  33.36877307,  73.80732532,\n",
    "#        -97.63618378,  63.64767343, -59.50050103, -82.1135804 ,\n",
    "#         77.1921181 , -49.07060001, -83.14296263,  20.58923936,\n",
    "#         22.45407113, -60.34021219,  93.07392893,  66.8388894 ,\n",
    "#        -53.42301689, -64.53013567,  34.68704473,  40.19995135,\n",
    "#        -20.92426576,  -6.45971336, -27.03420895,  -5.00038901,\n",
    "#        -65.3913821 , -31.87113074,  43.80992814])\n",
    "\n",
    "# theta1 = all_weights[:40]\n",
    "# theta2 = all_weights[40:]\n",
    "# theta1 = theta1.reshape((10, 4))\n",
    "# theta2 = theta2.reshape((3, 10))\n",
    "\n",
    "theta1 = all_weights[:40]\n",
    "bias1 = all_weights[40:50]\n",
    "theta2 = all_weights[50:80]\n",
    "bias2 = all_weights[80:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.set_weights([theta1.T, bias1, theta2.T, bias2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 1.1112 - acc: 0.5800\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 195us/step - loss: 0.8384 - acc: 0.6600\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 342us/step - loss: 0.7445 - acc: 0.6900\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.7015 - acc: 0.7300\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 271us/step - loss: 0.6649 - acc: 0.7500\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.6391 - acc: 0.7100\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.6141 - acc: 0.7100\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.5967 - acc: 0.7100\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 404us/step - loss: 0.5823 - acc: 0.7000\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 452us/step - loss: 0.5712 - acc: 0.6900\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 534us/step - loss: 0.5569 - acc: 0.7100\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 491us/step - loss: 0.5503 - acc: 0.7200\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.5420 - acc: 0.7300\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.5291 - acc: 0.7300\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.5177 - acc: 0.7700\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.5122 - acc: 0.7000\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.5077 - acc: 0.7400\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.4992 - acc: 0.7500\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.4955 - acc: 0.7200\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.4904 - acc: 0.7700\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.4817 - acc: 0.7500\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.4758 - acc: 0.7300\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.4740 - acc: 0.8100\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.4712 - acc: 0.8200\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.4642 - acc: 0.7700\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.4620 - acc: 0.7700\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.4586 - acc: 0.7800\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 287us/step - loss: 0.4503 - acc: 0.8100\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 305us/step - loss: 0.4482 - acc: 0.8100\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.4401 - acc: 0.8300\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 322us/step - loss: 0.4375 - acc: 0.8000\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.4378 - acc: 0.8500\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 285us/step - loss: 0.4284 - acc: 0.8100\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 273us/step - loss: 0.4269 - acc: 0.8000\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.4279 - acc: 0.8200\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 307us/step - loss: 0.4199 - acc: 0.8800\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 291us/step - loss: 0.4151 - acc: 0.8100\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.4131 - acc: 0.8500\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.4101 - acc: 0.8200\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.4079 - acc: 0.8400\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.3984 - acc: 0.8700\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 472us/step - loss: 0.3956 - acc: 0.8600\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 268us/step - loss: 0.3982 - acc: 0.8700\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.3914 - acc: 0.8700\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.3832 - acc: 0.8800\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.3840 - acc: 0.8600\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.3836 - acc: 0.8600\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 254us/step - loss: 0.3779 - acc: 0.8900\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 317us/step - loss: 0.3746 - acc: 0.8800\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.3739 - acc: 0.8600\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.3680 - acc: 0.8800\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 367us/step - loss: 0.3693 - acc: 0.8800\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 327us/step - loss: 0.3663 - acc: 0.8800\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.3595 - acc: 0.8800\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.3597 - acc: 0.8600\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.3573 - acc: 0.8800\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.3545 - acc: 0.8800\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.3461 - acc: 0.9000\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 248us/step - loss: 0.3446 - acc: 0.9200\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 305us/step - loss: 0.3452 - acc: 0.8800\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.3399 - acc: 0.9300\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 461us/step - loss: 0.3376 - acc: 0.8900\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 704us/step - loss: 0.3332 - acc: 0.9300\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 760us/step - loss: 0.3303 - acc: 0.9000\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 745us/step - loss: 0.3290 - acc: 0.9300\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.3244 - acc: 0.9300\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.3234 - acc: 0.9000\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 377us/step - loss: 0.3195 - acc: 0.9200\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.3269 - acc: 0.9000\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.3171 - acc: 0.9100\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.3128 - acc: 0.8800\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 386us/step - loss: 0.3123 - acc: 0.9100\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 496us/step - loss: 0.3107 - acc: 0.9400\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 476us/step - loss: 0.3027 - acc: 0.9400\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 857us/step - loss: 0.3009 - acc: 0.9300\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 560us/step - loss: 0.3027 - acc: 0.9400\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.2952 - acc: 0.9400\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.3030 - acc: 0.9300\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.2964 - acc: 0.9300\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.2906 - acc: 0.9300\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.2858 - acc: 0.9300\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.2920 - acc: 0.9100\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 516us/step - loss: 0.2841 - acc: 0.9400\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 517us/step - loss: 0.2795 - acc: 0.9500\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 498us/step - loss: 0.2832 - acc: 0.9500\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.2804 - acc: 0.9200\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 560us/step - loss: 0.2870 - acc: 0.9300\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 514us/step - loss: 0.2800 - acc: 0.9200\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.2739 - acc: 0.9500\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 486us/step - loss: 0.2667 - acc: 0.9400\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 303us/step - loss: 0.2753 - acc: 0.9200\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 442us/step - loss: 0.2669 - acc: 0.9400\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.2635 - acc: 0.9300\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.2604 - acc: 0.9600\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 405us/step - loss: 0.2701 - acc: 0.9300\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 271us/step - loss: 0.2570 - acc: 0.9600\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.2581 - acc: 0.9300\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.2527 - acc: 0.9400\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.2689 - acc: 0.9200\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 469us/step - loss: 0.2519 - acc: 0.9400\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.2509 - acc: 0.9500\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 464us/step - loss: 0.2487 - acc: 0.9400\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 556us/step - loss: 0.2531 - acc: 0.9100\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 300us/step - loss: 0.2435 - acc: 0.9500\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 354us/step - loss: 0.2370 - acc: 0.9600\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.2442 - acc: 0.9200\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 480us/step - loss: 0.2348 - acc: 0.9400\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.2378 - acc: 0.9500\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.2354 - acc: 0.9500\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.2364 - acc: 0.9300\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.2301 - acc: 0.9600\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 331us/step - loss: 0.2341 - acc: 0.9400\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 475us/step - loss: 0.2253 - acc: 0.9500\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.2334 - acc: 0.9500\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.2287 - acc: 0.9500\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 322us/step - loss: 0.2292 - acc: 0.9500\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.2238 - acc: 0.9200\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.2223 - acc: 0.9500\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 285us/step - loss: 0.2197 - acc: 0.9400\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 522us/step - loss: 0.2199 - acc: 0.9500\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.2178 - acc: 0.9600\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.2144 - acc: 0.9700\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 282us/step - loss: 0.2133 - acc: 0.9600\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.2205 - acc: 0.9700\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.2214 - acc: 0.9200\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.2216 - acc: 0.9400\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.2088 - acc: 0.9400\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.2134 - acc: 0.9500\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.2113 - acc: 0.9400\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.2061 - acc: 0.9600\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.2117 - acc: 0.9400\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.2050 - acc: 0.9400\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.2067 - acc: 0.9600\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.2038 - acc: 0.9500\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.1980 - acc: 0.9500\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.2023 - acc: 0.9600\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.1982 - acc: 0.9500\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 467us/step - loss: 0.2068 - acc: 0.9600\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.1951 - acc: 0.9500\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.1976 - acc: 0.9600\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.1948 - acc: 0.9600\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 367us/step - loss: 0.1920 - acc: 0.9700\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.1982 - acc: 0.9200\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.1957 - acc: 0.9500\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.1934 - acc: 0.9500\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.2001 - acc: 0.9100\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 439us/step - loss: 0.1962 - acc: 0.9400\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.1900 - acc: 0.9600\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1861 - acc: 0.9600\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.1867 - acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10282ce50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 96.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.14348114,  0.21639578, -0.44729847,  0.8295948 ,  0.16641778,\n",
       "         -0.07767367, -0.12728068, -0.28208253,  0.22074868,  0.509552  ],\n",
       "        [-0.61754966, -0.5896579 ,  0.00157642,  1.1432313 , -0.62714976,\n",
       "         -0.4004094 , -0.37114578,  0.16888201, -0.00739633,  0.38578534],\n",
       "        [-0.36741218,  0.5155627 , -0.6315781 , -1.3509495 , -0.16172144,\n",
       "         -0.30461136,  1.2335435 , -0.48711225, -0.06261458, -0.529389  ],\n",
       "        [ 0.1153602 , -0.04333492, -0.2583912 , -0.26051065, -0.49223548,\n",
       "         -0.4701106 ,  0.6810271 , -0.34814483, -0.166393  ,  0.20246936]],\n",
       "       dtype=float32),\n",
       " array([ 0.        , -0.06604207,  0.        ,  0.25740272,  0.        ,\n",
       "         0.        , -0.10687702,  0.        ,  0.07080218,  0.11607458],\n",
       "       dtype=float32),\n",
       " array([[-0.41601363, -0.3122657 ,  0.5407959 ],\n",
       "        [-0.23056379, -0.23473522,  0.10454617],\n",
       "        [-0.48208797, -0.43441623, -0.41507402],\n",
       "        [ 1.3570794 ,  0.32936567, -1.2168286 ],\n",
       "        [ 0.63038766,  0.50303197, -0.55589443],\n",
       "        [-0.18804592, -0.58184975, -0.3813505 ],\n",
       "        [-1.2522227 , -0.00844393,  0.8844975 ],\n",
       "        [-0.32531413,  0.4480245 ,  0.62772   ],\n",
       "        [ 0.20608045,  0.4815198 ,  0.02336541],\n",
       "        [-0.24376097,  0.24185449, -0.62287843]], dtype=float32),\n",
       " array([ 0.04722025,  0.15697604, -0.2041966 ], dtype=float32)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
