{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent Neural Networl training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the realisation of neural network training with SGD. You can initialize the network with weights in form of 1D list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initialisation.\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width            class\n",
       "0           4.8          3.4           1.9          0.2      Iris-setosa\n",
       "1           5.8          4.0           1.2          0.2      Iris-setosa\n",
       "2           5.1          3.8           1.9          0.4      Iris-setosa\n",
       "3           5.5          2.4           3.8          1.1  Iris-versicolor\n",
       "4           5.5          2.4           3.7          1.0  Iris-versicolor\n",
       "5           5.7          3.0           4.2          1.2  Iris-versicolor\n",
       "6           7.2          3.0           5.8          1.6   Iris-virginica\n",
       "7           5.0          2.0           3.5          1.0  Iris-versicolor\n",
       "8           5.1          3.7           1.5          0.4      Iris-setosa\n",
       "9           5.8          2.8           5.1          2.4   Iris-virginica"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading dataset from text file.\n",
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "\n",
    "# Shuffling dataset and displaying top 10 rows.\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.132068</td>\n",
       "      <td>0.078636</td>\n",
       "      <td>-0.269372</td>\n",
       "      <td>-0.399467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005485</td>\n",
       "      <td>0.215000</td>\n",
       "      <td>-0.370821</td>\n",
       "      <td>-0.399467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.094093</td>\n",
       "      <td>0.169545</td>\n",
       "      <td>-0.269372</td>\n",
       "      <td>-0.319467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.043460</td>\n",
       "      <td>-0.148636</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.043460</td>\n",
       "      <td>-0.148636</td>\n",
       "      <td>-0.008502</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.018143</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.063961</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.171730</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.295845</td>\n",
       "      <td>0.160533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.106751</td>\n",
       "      <td>-0.239545</td>\n",
       "      <td>-0.037488</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.094093</td>\n",
       "      <td>0.146818</td>\n",
       "      <td>-0.327343</td>\n",
       "      <td>-0.319467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.005485</td>\n",
       "      <td>-0.057727</td>\n",
       "      <td>0.194396</td>\n",
       "      <td>0.480533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  class\n",
       "0     -0.132068     0.078636     -0.269372    -0.399467      0\n",
       "1     -0.005485     0.215000     -0.370821    -0.399467      0\n",
       "2     -0.094093     0.169545     -0.269372    -0.319467      0\n",
       "3     -0.043460    -0.148636      0.005990    -0.039467      1\n",
       "4     -0.043460    -0.148636     -0.008502    -0.079467      1\n",
       "5     -0.018143    -0.012273      0.063961     0.000533      1\n",
       "6      0.171730    -0.012273      0.295845     0.160533      2\n",
       "7     -0.106751    -0.239545     -0.037488    -0.079467      1\n",
       "8     -0.094093     0.146818     -0.327343    -0.319467      0\n",
       "9     -0.005485    -0.057727      0.194396     0.480533      2"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data standartization\n",
    "for label in list(dataset)[:-1]:\n",
    "    dataset[label] = (dataset[label] - dataset[label].mean()) / dataset[label].abs().max()\n",
    "\n",
    "# Mapping classes to numbers.\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "\n",
    "# Dividing dataset into training adn testing subsets.\n",
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "# Numpy array from pandas DataFrame\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "\n",
    "# Transforming vector of classes into matrix of classes.\n",
    "y = to_categorical(y)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Displaying top 10 rows after all tranformations.\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can paste every weights you want, and network will be initialised with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing basic weights.\n",
    "all_weights = np.array([-0.74464946, -0.58780526,  1.41413286,  1.56612411,  0.89748166,\n",
    "\t1.26587933, -1.7823427 , -1.74265063,  0.8177892 , -0.04201371,\n",
    "\t1.93503724,  0.47859909,  0.45392613, -1.78392789,  1.01074704,\n",
    "\t1.83660519,  1.74030175, -0.10822437, -1.30336803, -1.77002355,\n",
    "\t-0.40594965, -0.70434178, -1.41642537, -1.91579606,  0.18598574,\n",
    "\t-0.88166189,  1.84681131,  0.96850258, -1.09169225,  0.88481126,\n",
    "\t-1.8010207 , -1.9930251 ,  0.55270947, -1.51767629, -1.35514934,\n",
    "\t-1.56836933,  0.7268226 , -0.81680452,  1.91438837,  0.98525988,\n",
    "\t0.02142366,  1.57358414, -0.29674495, -0.1720991 , -0.24934692,\n",
    "\t1.37585919,  1.6708461 ,  0.51438577,  1.55851392,  0.83227882,\n",
    "\t-0.20616961,  1.36950349, -1.55857974, -0.78808741,  0.58527486,\n",
    "\t1.63512289, -1.99569004,  1.75354475,  1.67869191, -1.99586462,\n",
    "\t-1.39584755,  1.6807379 , -1.22949897, -1.70944359, -1.13868966,\n",
    "\t0.97626506,  1.7376651 , -1.72645829,  0.27143495, -0.94191227,\n",
    "\t1.40813308, -0.90983758,  1.17556797,  1.80804884, -1.42273582,\n",
    "\t-1.55310948,  1.64272254, -1.71808112, -1.66268147,  1.83550087,\n",
    "\t-1.70728038,  1.52401379, -1.29365514])\n",
    "\n",
    "#  Reshaping 1D input weights to 2 2D matrix and bias vectors.\n",
    "theta1 = all_weights[:40]\n",
    "bias1 = all_weights[40:50]\n",
    "theta2 = all_weights[50:80]\n",
    "bias2 = all_weights[80:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model and initialising weights with random values.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 113us/step\n",
      "50/50 [==============================] - 0s 133us/step\n"
     ]
    }
   ],
   "source": [
    "# Initialising network with custom weights.\n",
    "model.set_weights([theta1.T, bias1, theta2.T, bias2])\n",
    "\n",
    "# Evaluating model accuracy of train and test set without SGD.\n",
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 94.00%\n",
      "Test:\n",
      "acc: 94.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 0s 255us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 258us/step - loss: 0.0497 - acc: 0.9700\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.0493 - acc: 0.9700\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.0496 - acc: 0.9700\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.0495 - acc: 0.9700\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0493 - acc: 0.9700\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 347us/step - loss: 0.0499 - acc: 0.9700\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 364us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0493 - acc: 0.9700\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 311us/step - loss: 0.0497 - acc: 0.9700\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.0495 - acc: 0.9700\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.0494 - acc: 0.9700\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0491 - acc: 0.9700\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0491 - acc: 0.9700\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 362us/step - loss: 0.0491 - acc: 0.9800\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 419us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 454us/step - loss: 0.0494 - acc: 0.9700\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0491 - acc: 0.9800\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0491 - acc: 0.9700\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.0490 - acc: 0.9700\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0491 - acc: 0.9700\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.0493 - acc: 0.9700\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0487 - acc: 0.9700\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.0491 - acc: 0.9700\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0489 - acc: 0.9800\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.0487 - acc: 0.9700\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.0496 - acc: 0.9700\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 367us/step - loss: 0.0490 - acc: 0.9700\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.0488 - acc: 0.9700\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0487 - acc: 0.9800\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.0490 - acc: 0.9700\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0491 - acc: 0.9800\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0489 - acc: 0.9700\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.0492 - acc: 0.9700\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0490 - acc: 0.9700\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 467us/step - loss: 0.0487 - acc: 0.9800\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 367us/step - loss: 0.0487 - acc: 0.9700\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.0489 - acc: 0.9700\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.0489 - acc: 0.9700\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.0488 - acc: 0.9700\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 362us/step - loss: 0.0488 - acc: 0.9700\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0490 - acc: 0.9800\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 509us/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0485 - acc: 0.9800\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0490 - acc: 0.9800\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 551us/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0487 - acc: 0.9800\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 492us/step - loss: 0.0485 - acc: 0.9800\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.0485 - acc: 0.9800\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 367us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 327us/step - loss: 0.0484 - acc: 0.9800\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 342us/step - loss: 0.0485 - acc: 0.9700\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.0483 - acc: 0.9800\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.0483 - acc: 0.9700\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0484 - acc: 0.9800\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.0483 - acc: 0.9800\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.0487 - acc: 0.9700\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 342us/step - loss: 0.0483 - acc: 0.9800\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.0489 - acc: 0.9800\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.0482 - acc: 0.9800\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0484 - acc: 0.9800\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0484 - acc: 0.9800\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 330us/step - loss: 0.0484 - acc: 0.9800\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 325us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.0485 - acc: 0.9800\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 386us/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.0482 - acc: 0.9800\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 463us/step - loss: 0.0482 - acc: 0.9800\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 485us/step - loss: 0.0480 - acc: 0.9800\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 262us/step - loss: 0.0482 - acc: 0.9800\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 293us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 302us/step - loss: 0.0486 - acc: 0.9800\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.0480 - acc: 0.9800\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 467us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 301us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 448us/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0483 - acc: 0.9800\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 477us/step - loss: 0.0480 - acc: 0.9800\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.0482 - acc: 0.9800\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 463us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 474us/step - loss: 0.0482 - acc: 0.9800\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.0481 - acc: 0.9800\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0480 - acc: 0.9800\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 325us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 412us/step - loss: 0.0477 - acc: 0.9800\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0484 - acc: 0.9800\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 327us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 246us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 312us/step - loss: 0.0477 - acc: 0.9800\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 426us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 757us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 330us/step - loss: 0.0477 - acc: 0.9800\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.0475 - acc: 0.9800\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 347us/step - loss: 0.0480 - acc: 0.9800\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.0473 - acc: 0.9800\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.0478 - acc: 0.9800\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 276us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.0475 - acc: 0.9800\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.0474 - acc: 0.9800\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 316us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.0473 - acc: 0.9800\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0475 - acc: 0.9800\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.0474 - acc: 0.9800\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0476 - acc: 0.9800\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0474 - acc: 0.9800\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0471 - acc: 0.9800\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.0473 - acc: 0.9800\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.0475 - acc: 0.9800\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 466us/step - loss: 0.0473 - acc: 0.9800\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0473 - acc: 0.9800\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0473 - acc: 0.9800\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 328us/step - loss: 0.0475 - acc: 0.9800\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.0473 - acc: 0.9800\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0472 - acc: 0.9800\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 268us/step - loss: 0.0470 - acc: 0.9800\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.0474 - acc: 0.9800\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.0473 - acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1822d39650>"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training neural network with SGD\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 141us/step\n",
      "50/50 [==============================] - 0s 151us/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluating nueral netwok accuracy after SGD.\n",
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 98.00%\n",
      "Test:\n",
      "acc: 96.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
