{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width            class\n",
       "0           6.4          2.8           5.6          2.1   Iris-virginica\n",
       "1           5.2          2.7           3.9          1.4  Iris-versicolor\n",
       "2           4.8          3.0           1.4          0.3      Iris-setosa\n",
       "3           5.2          4.1           1.5          0.1      Iris-setosa\n",
       "4           4.6          3.1           1.5          0.2      Iris-setosa\n",
       "5           6.1          2.8           4.0          1.3  Iris-versicolor\n",
       "6           6.0          2.9           4.5          1.5  Iris-versicolor\n",
       "7           4.9          3.0           1.4          0.2      Iris-setosa\n",
       "8           7.7          2.8           6.7          2.0   Iris-virginica\n",
       "9           4.8          3.4           1.9          0.2      Iris-setosa"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.070464</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>0.078454</td>\n",
       "      <td>0.040533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.070464</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>0.252367</td>\n",
       "      <td>0.240533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.083122</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.252367</td>\n",
       "      <td>0.240533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.106751</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.066473</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>-0.132068</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>-0.341836</td>\n",
       "      <td>-0.439467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081435</td>\n",
       "      <td>-0.080455</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>0.080533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.081435</td>\n",
       "      <td>0.237727</td>\n",
       "      <td>-0.327343</td>\n",
       "      <td>-0.439467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.121097</td>\n",
       "      <td>0.033182</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>0.440533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.095781</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.092947</td>\n",
       "      <td>0.080533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.032489</td>\n",
       "      <td>-0.103182</td>\n",
       "      <td>0.266860</td>\n",
       "      <td>0.080533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  class\n",
       "17       0.070464    -0.035000      0.078454     0.040533      1\n",
       "82       0.070464     0.010455      0.252367     0.240533      2\n",
       "117      0.083122    -0.012273      0.252367     0.240533      2\n",
       "69      -0.106751    -0.171364     -0.066473    -0.079467      1\n",
       "130     -0.132068    -0.012273     -0.341836    -0.439467      0\n",
       "1       -0.081435    -0.080455      0.020483     0.080533      1\n",
       "3       -0.081435     0.237727     -0.327343    -0.439467      0\n",
       "62       0.121097     0.033182      0.310338     0.440533      2\n",
       "39       0.095781    -0.012273      0.092947     0.080533      1\n",
       "136      0.032489    -0.103182      0.266860     0.080533      2"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data standartization\n",
    "for label in list(dataset)[:-1]:\n",
    "    dataset[label] = (dataset[label] - dataset[label].mean()) / dataset[label].abs().max()\n",
    "\n",
    "# Mapping classes to numbers.\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "\n",
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing basic weights.\n",
    "\n",
    "all_weights = np.array([-0.11956666,  1.60757496, -1.60115118, -0.01512596, -0.63268727,\n",
    "        0.04287272,  0.7845708 , -1.98334794,  0.05424702,  0.08041573,\n",
    "        1.86520092,  0.84061018,  0.19273817,  1.58142388, -1.18296091,\n",
    "       -0.36947794, -1.82491911, -1.3585935 ,  1.43440512,  1.25264398,\n",
    "       -1.87437234, -0.96126959, -0.19941367, -1.99482165,  1.60326499,\n",
    "       -1.10554801, -0.80067292, -0.03431882, -1.49743684,  1.74736905,\n",
    "       -1.43940704, -1.70685305,  0.81107803,  0.38819742,  1.6753215 ,\n",
    "        1.27688657,  0.13276105, -1.25716079,  1.67214695, -0.15582424,\n",
    "        0.87290021,  0.73139845,  1.21441429, -0.75315388, -1.16677647,\n",
    "       -0.5926008 , -1.08107115,  1.36668028,  1.96621121, -0.3339175 ,\n",
    "        1.86446984,  1.25271354, -1.02780653, -0.80520123, -0.44166891,\n",
    "        0.70027392, -0.76132972,  1.32227312, -0.8358854 , -0.04059621,\n",
    "       -1.46407095,  1.25734053,  0.66699922, -1.12802165, -1.03722805,\n",
    "        0.49884331, -1.80602096, -1.06096596, -1.50958309, -0.32203364,\n",
    "       -0.68736231,  0.01052929,  1.96004013, -1.46459389,  0.68320843,\n",
    "       -1.61925607,  0.26758798, -1.68382157,  1.9233228 ,  1.53693003,\n",
    "        1.30071251, -1.22386937, -0.42051178])\n",
    "\n",
    "#  Reshaping 1D input weights to 2 2D matrix and bias vectors.\n",
    "theta1 = all_weights[:40]\n",
    "bias1 = all_weights[40:50]\n",
    "theta2 = all_weights[50:80]\n",
    "bias2 = all_weights[80:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 10ms/step\n",
      "50/50 [==============================] - 0s 159us/step\n"
     ]
    }
   ],
   "source": [
    "#model.set_weights([theta1.T, bias1, theta2.T, bias2])\n",
    "\n",
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 15.00%\n",
      "Test:\n",
      "acc: 24.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 1.0938 - acc: 0.1700\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 366us/step - loss: 1.0814 - acc: 0.4600\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 435us/step - loss: 1.0703 - acc: 0.4900\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 448us/step - loss: 1.0603 - acc: 0.4600\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 457us/step - loss: 1.0513 - acc: 0.4700\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 414us/step - loss: 1.0432 - acc: 0.4400\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 556us/step - loss: 1.0358 - acc: 0.4200\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 629us/step - loss: 1.0286 - acc: 0.4200\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 470us/step - loss: 1.0220 - acc: 0.4200\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 462us/step - loss: 1.0149 - acc: 0.4200\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 421us/step - loss: 1.0077 - acc: 0.4200\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 356us/step - loss: 1.0004 - acc: 0.4200\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.9924 - acc: 0.4100\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 436us/step - loss: 0.9842 - acc: 0.4600\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 505us/step - loss: 0.9767 - acc: 0.5100\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 806us/step - loss: 0.9691 - acc: 0.5500\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 826us/step - loss: 0.9614 - acc: 0.5900\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 500us/step - loss: 0.9541 - acc: 0.6100\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.9465 - acc: 0.6200\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.9394 - acc: 0.6300\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.9321 - acc: 0.6500\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 595us/step - loss: 0.9244 - acc: 0.6800\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 471us/step - loss: 0.9175 - acc: 0.7000\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 643us/step - loss: 0.9100 - acc: 0.7000\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.9025 - acc: 0.7000\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 452us/step - loss: 0.8952 - acc: 0.7000\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.8875 - acc: 0.7000\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.8802 - acc: 0.7000\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.8727 - acc: 0.7100\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.8655 - acc: 0.7100\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.8580 - acc: 0.7100\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.8505 - acc: 0.7100\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.8433 - acc: 0.7100\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 806us/step - loss: 0.8361 - acc: 0.7100\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 787us/step - loss: 0.8287 - acc: 0.7100\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 418us/step - loss: 0.8214 - acc: 0.7100\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.8138 - acc: 0.7100\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.8069 - acc: 0.7100\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.7997 - acc: 0.7100\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 364us/step - loss: 0.7930 - acc: 0.7100\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.7854 - acc: 0.7100\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.7782 - acc: 0.7100\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.7713 - acc: 0.7100\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.7644 - acc: 0.7100\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.7576 - acc: 0.7100\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.7507 - acc: 0.7100\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.7440 - acc: 0.7100\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.7372 - acc: 0.7100\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 470us/step - loss: 0.7304 - acc: 0.7100\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 403us/step - loss: 0.7241 - acc: 0.7100\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 553us/step - loss: 0.7174 - acc: 0.7100\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.7113 - acc: 0.7100\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.7050 - acc: 0.7100\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 524us/step - loss: 0.6983 - acc: 0.7100\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.6922 - acc: 0.7100\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.6859 - acc: 0.7100\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 443us/step - loss: 0.6799 - acc: 0.7100\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 517us/step - loss: 0.6741 - acc: 0.7100\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 606us/step - loss: 0.6679 - acc: 0.7100\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 407us/step - loss: 0.6622 - acc: 0.7100\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 455us/step - loss: 0.6564 - acc: 0.7100\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 537us/step - loss: 0.6506 - acc: 0.7100\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.6450 - acc: 0.7100\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.6396 - acc: 0.7100\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.6343 - acc: 0.7100\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.6290 - acc: 0.7100\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.6239 - acc: 0.7100\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 426us/step - loss: 0.6185 - acc: 0.7100\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.6134 - acc: 0.7100\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.6083 - acc: 0.7100\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.6035 - acc: 0.7100\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.5988 - acc: 0.7100\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.5941 - acc: 0.7100\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.5892 - acc: 0.7200\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.5846 - acc: 0.7200\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 606us/step - loss: 0.5803 - acc: 0.7300\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.5757 - acc: 0.7400\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.5715 - acc: 0.7300\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.5673 - acc: 0.7400\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.5630 - acc: 0.7500\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 305us/step - loss: 0.5587 - acc: 0.7400\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 297us/step - loss: 0.5547 - acc: 0.7400\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 290us/step - loss: 0.5506 - acc: 0.7500\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.5468 - acc: 0.7500\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 342us/step - loss: 0.5428 - acc: 0.7600\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.5392 - acc: 0.7700\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 277us/step - loss: 0.5355 - acc: 0.7600\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 255us/step - loss: 0.5315 - acc: 0.7800\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.5281 - acc: 0.7800\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 265us/step - loss: 0.5243 - acc: 0.7800\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 252us/step - loss: 0.5208 - acc: 0.7900\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.5172 - acc: 0.7800\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.5140 - acc: 0.7800\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 308us/step - loss: 0.5108 - acc: 0.7800\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 461us/step - loss: 0.5075 - acc: 0.8000\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.5040 - acc: 0.7900\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 485us/step - loss: 0.5010 - acc: 0.7900\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.4979 - acc: 0.8000\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.4947 - acc: 0.8000\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.4915 - acc: 0.8000\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.4885 - acc: 0.8100\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.4860 - acc: 0.8200\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.4828 - acc: 0.8200\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.4801 - acc: 0.8200\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.4771 - acc: 0.8400\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 453us/step - loss: 0.4743 - acc: 0.8500\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.4721 - acc: 0.8600\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.4689 - acc: 0.8600\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.4661 - acc: 0.8700\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.4634 - acc: 0.8700\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.4608 - acc: 0.8800\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.4584 - acc: 0.8900\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.4560 - acc: 0.8900\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 305us/step - loss: 0.4536 - acc: 0.8900\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.4508 - acc: 0.8900\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 254us/step - loss: 0.4482 - acc: 0.8900\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 384us/step - loss: 0.4460 - acc: 0.8900\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 325us/step - loss: 0.4436 - acc: 0.8900\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.4413 - acc: 0.9000\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.4391 - acc: 0.9000\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 325us/step - loss: 0.4365 - acc: 0.9000\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.4343 - acc: 0.9000\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.4320 - acc: 0.9000\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.4300 - acc: 0.9000\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 295us/step - loss: 0.4278 - acc: 0.9000\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.4256 - acc: 0.9000\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.4233 - acc: 0.9000\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.4214 - acc: 0.9000\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.4190 - acc: 0.9000\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.4170 - acc: 0.9000\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.4151 - acc: 0.9000\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 347us/step - loss: 0.4130 - acc: 0.9000\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 441us/step - loss: 0.4108 - acc: 0.9000\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.4088 - acc: 0.9000\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.4071 - acc: 0.9000\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 295us/step - loss: 0.4055 - acc: 0.9000\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.4030 - acc: 0.9000\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 308us/step - loss: 0.4010 - acc: 0.9100\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 294us/step - loss: 0.3991 - acc: 0.9000\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.3974 - acc: 0.9300\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.3952 - acc: 0.9100\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 245us/step - loss: 0.3935 - acc: 0.9200\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.3920 - acc: 0.9200\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 301us/step - loss: 0.3898 - acc: 0.9300\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 482us/step - loss: 0.3879 - acc: 0.9300\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.3862 - acc: 0.9300\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 301us/step - loss: 0.3843 - acc: 0.9300\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 317us/step - loss: 0.3826 - acc: 0.9300\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.3810 - acc: 0.9300\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.3790 - acc: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1820415ad0>"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 160us/step\n",
      "50/50 [==============================] - 0s 147us/step\n"
     ]
    }
   ],
   "source": [
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 94.00%\n",
      "Test:\n",
      "acc: 84.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.12129605,  1.1414499 ,  1.8287032 ,  1.197967  , -0.23940828,\n",
       "          1.5388327 , -2.0305076 , -1.2679032 , -1.3921349 ,  1.2141073 ],\n",
       "        [-1.528534  ,  1.2004582 ,  1.132461  , -0.9021921 ,  0.12258842,\n",
       "         -1.7715137 ,  1.9272462 ,  0.7180337 , -1.5698389 ,  1.557972  ],\n",
       "        [ 0.1908095 , -2.1938727 , -1.9225051 ,  0.18214469,  0.5943558 ,\n",
       "          2.061206  ,  1.0078062 ,  0.0305413 , -0.8459417 , -1.7095819 ],\n",
       "        [-0.24911903, -1.6868356 , -0.29562044, -1.9896674 ,  0.9614039 ,\n",
       "          2.1186361 , -0.11543606, -0.45685276, -1.1881891 , -2.0133252 ]],\n",
       "       dtype=float32),\n",
       " array([-0.4369997 ,  0.83060896, -1.125353  ,  0.6968958 , -1.2465042 ,\n",
       "         0.4252797 , -0.06002772, -0.6161836 ,  0.10193942,  0.90474343],\n",
       "       dtype=float32),\n",
       " array([[-1.9974568 , -1.1079164 ,  0.74428606],\n",
       "        [ 1.3465135 , -0.78044224, -1.7003281 ],\n",
       "        [ 1.3785197 ,  0.71266013,  1.9570906 ],\n",
       "        [ 0.7566066 ,  1.8074772 , -1.8238305 ],\n",
       "        [ 0.64990187, -0.5158149 ,  0.97621155],\n",
       "        [-1.9250046 , -0.87008476,  2.367424  ],\n",
       "        [-0.05205862,  1.3140781 , -1.7909278 ],\n",
       "        [ 1.7291831 , -0.9945487 , -1.265376  ],\n",
       "        [ 0.87581617,  0.35152644, -1.0939636 ],\n",
       "        [ 1.7039464 ,  0.46797618, -1.7524608 ]], dtype=float32),\n",
       " array([-1.8978047,  1.3257744, -0.3753495], dtype=float32)]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
