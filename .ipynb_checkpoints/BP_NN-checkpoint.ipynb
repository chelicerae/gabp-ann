{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  class\n",
       "0           5.0          3.5           1.3          0.3      0\n",
       "1           4.5          2.3           1.3          0.3      0\n",
       "2           7.4          2.8           6.1          1.9      2\n",
       "3           5.8          2.7           5.1          1.9      2\n",
       "4           5.0          2.3           3.3          1.0      1\n",
       "5           6.2          2.2           4.5          1.5      1\n",
       "6           4.9          3.1           1.5          0.1      0\n",
       "7           5.5          2.6           4.4          1.2      1\n",
       "8           5.5          2.3           4.0          1.3      1\n",
       "9           6.0          2.9           4.5          1.5      1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal length  sepal width  petal length  petal width  class\n",
      "100           5.7          2.9           4.2          1.3      1\n",
      "101           6.0          3.0           4.8          1.8      2\n",
      "102           5.6          3.0           4.1          1.3      1\n",
      "103           5.6          2.9           3.6          1.3      1\n",
      "104           5.4          3.7           1.5          0.2      0\n",
      "105           6.9          3.2           5.7          2.3      2\n",
      "106           5.9          3.2           4.8          1.8      1\n",
      "107           5.1          3.5           1.4          0.3      0\n",
      "108           4.6          3.6           1.0          0.2      0\n",
      "109           5.5          4.2           1.4          0.2      0\n",
      "110           4.8          3.1           1.6          0.2      0\n",
      "111           6.3          2.5           4.9          1.5      1\n",
      "112           7.2          3.6           6.1          2.5      2\n",
      "113           6.3          3.3           4.7          1.6      1\n",
      "114           6.5          3.2           5.1          2.0      2\n",
      "115           6.0          2.2           5.0          1.5      2\n",
      "116           4.8          3.0           1.4          0.1      0\n",
      "117           6.6          3.0           4.4          1.4      1\n",
      "118           7.6          3.0           6.6          2.1      2\n",
      "119           5.2          3.5           1.5          0.2      0\n",
      "120           5.8          2.7           3.9          1.2      1\n",
      "121           5.2          2.7           3.9          1.4      1\n",
      "122           6.3          3.3           6.0          2.5      2\n",
      "123           5.1          3.4           1.5          0.2      0\n",
      "124           6.3          3.4           5.6          2.4      2\n",
      "125           6.4          2.9           4.3          1.3      1\n",
      "126           6.1          2.9           4.7          1.4      1\n",
      "127           5.8          2.8           5.1          2.4      2\n",
      "128           5.0          3.4           1.5          0.2      0\n",
      "129           6.7          3.0           5.0          1.7      1\n",
      "130           7.7          3.8           6.7          2.2      2\n",
      "131           6.2          2.9           4.3          1.3      1\n",
      "132           4.6          3.2           1.4          0.2      0\n",
      "133           5.1          3.8           1.6          0.2      0\n",
      "134           6.1          2.8           4.0          1.3      1\n",
      "135           7.3          2.9           6.3          1.8      2\n",
      "136           6.4          2.8           5.6          2.2      2\n",
      "137           6.0          2.7           5.1          1.6      1\n",
      "138           6.7          3.1           4.7          1.5      1\n",
      "139           5.7          2.8           4.5          1.3      1\n",
      "140           6.4          3.2           4.5          1.5      1\n",
      "141           6.7          3.3           5.7          2.5      2\n",
      "142           5.4          3.4           1.7          0.2      0\n",
      "143           5.5          2.5           4.0          1.3      1\n",
      "144           5.9          3.0           4.2          1.5      1\n",
      "145           4.9          2.4           3.3          1.0      1\n",
      "146           5.6          2.5           3.9          1.1      1\n",
      "147           6.3          2.3           4.4          1.3      1\n",
      "148           5.7          2.8           4.1          1.3      1\n",
      "149           4.8          3.0           1.4          0.3      0\n"
     ]
    }
   ],
   "source": [
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = np.array([ 0.82850905,  0.40072448, -1.16062222,  0.24129967, -0.00901011,\n",
    "       -0.55042084,  0.17620743, -0.35640638,  0.28189825, -0.40337483,\n",
    "       -0.53330681,  0.1720898 ,  1.99998587, -0.0237903 , -1.99372395,\n",
    "       -1.53997806,  1.31316753, -1.85079916,  1.53083946,  1.20376128,\n",
    "        2.        , -1.03966506, -1.78537761, -0.57303334, -0.83020559,\n",
    "        1.2181045 , -0.95560658,  0.32555322, -0.01306465, -0.58740851,\n",
    "       -0.30109983,  2.        ,  1.7863003 ,  1.87352263, -1.2398616 ,\n",
    "       -1.35349408,  0.21784511,  2.        , -1.14411966, -0.96291608,\n",
    "        1.15340453, -0.12331424, -0.68801667,  1.76125887, -1.96991071,\n",
    "        0.88347918,  0.65414193, -0.13644339,  1.44238258,  1.31562074,\n",
    "       -0.95010176, -0.08231172, -0.42752867,  1.66501362,  0.62532375,\n",
    "        1.99714638,  0.73385111, -1.89800158, -0.01269442,  2.        ,\n",
    "       -0.34806914, -1.06161126,  0.13609927, -1.90406267,  1.64843287,\n",
    "       -1.89691344,  1.50997576,  1.82210462, -1.48688357, -2.        ])\n",
    "\n",
    "theta1 = all_weights[:40]\n",
    "theta2 = all_weights[40:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([theta1.T, [0]*10, theta2.T, [0]*3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "150/150 [==============================] - 0s 3ms/step - loss: 0.0448 - acc: 0.9933\n",
      "Epoch 2/150\n",
      "150/150 [==============================] - 0s 506us/step - loss: 0.0394 - acc: 0.9933\n",
      "Epoch 3/150\n",
      "150/150 [==============================] - 0s 783us/step - loss: 0.0393 - acc: 0.9800\n",
      "Epoch 4/150\n",
      "150/150 [==============================] - 0s 822us/step - loss: 0.0457 - acc: 0.9800\n",
      "Epoch 5/150\n",
      "150/150 [==============================] - 0s 584us/step - loss: 0.0384 - acc: 0.9933\n",
      "Epoch 6/150\n",
      "150/150 [==============================] - 0s 940us/step - loss: 0.0463 - acc: 0.9933\n",
      "Epoch 7/150\n",
      "150/150 [==============================] - 0s 367us/step - loss: 0.0407 - acc: 0.9867\n",
      "Epoch 8/150\n",
      "150/150 [==============================] - 0s 404us/step - loss: 0.0397 - acc: 0.9867\n",
      "Epoch 9/150\n",
      "150/150 [==============================] - 0s 351us/step - loss: 0.0431 - acc: 0.9800\n",
      "Epoch 10/150\n",
      "150/150 [==============================] - 0s 336us/step - loss: 0.0447 - acc: 0.9933\n",
      "Epoch 11/150\n",
      "150/150 [==============================] - 0s 324us/step - loss: 0.0470 - acc: 0.9800\n",
      "Epoch 12/150\n",
      "150/150 [==============================] - 0s 332us/step - loss: 0.0431 - acc: 0.9867\n",
      "Epoch 13/150\n",
      "150/150 [==============================] - 0s 303us/step - loss: 0.0429 - acc: 0.9933\n",
      "Epoch 14/150\n",
      "150/150 [==============================] - 0s 651us/step - loss: 0.0436 - acc: 0.9933\n",
      "Epoch 15/150\n",
      "150/150 [==============================] - 0s 482us/step - loss: 0.0448 - acc: 0.9867\n",
      "Epoch 16/150\n",
      "150/150 [==============================] - 0s 449us/step - loss: 0.0483 - acc: 0.9800\n",
      "Epoch 17/150\n",
      "150/150 [==============================] - 0s 650us/step - loss: 0.0442 - acc: 0.9867\n",
      "Epoch 18/150\n",
      "150/150 [==============================] - 0s 606us/step - loss: 0.0424 - acc: 0.9933\n",
      "Epoch 19/150\n",
      "150/150 [==============================] - 0s 355us/step - loss: 0.0433 - acc: 0.9867\n",
      "Epoch 20/150\n",
      "150/150 [==============================] - 0s 762us/step - loss: 0.0443 - acc: 0.9867\n",
      "Epoch 21/150\n",
      "150/150 [==============================] - 0s 575us/step - loss: 0.0415 - acc: 0.9933\n",
      "Epoch 22/150\n",
      "150/150 [==============================] - 0s 237us/step - loss: 0.0400 - acc: 0.9867\n",
      "Epoch 23/150\n",
      "150/150 [==============================] - 0s 318us/step - loss: 0.0482 - acc: 0.9867\n",
      "Epoch 24/150\n",
      "150/150 [==============================] - 0s 339us/step - loss: 0.0433 - acc: 0.9933\n",
      "Epoch 25/150\n",
      "150/150 [==============================] - 0s 712us/step - loss: 0.0442 - acc: 0.9933\n",
      "Epoch 26/150\n",
      "150/150 [==============================] - 0s 496us/step - loss: 0.0420 - acc: 0.9933\n",
      "Epoch 27/150\n",
      "150/150 [==============================] - 0s 529us/step - loss: 0.0388 - acc: 0.9933\n",
      "Epoch 28/150\n",
      "150/150 [==============================] - 0s 466us/step - loss: 0.0443 - acc: 0.9933\n",
      "Epoch 29/150\n",
      "150/150 [==============================] - 0s 663us/step - loss: 0.0420 - acc: 0.9867\n",
      "Epoch 30/150\n",
      "150/150 [==============================] - 0s 559us/step - loss: 0.0434 - acc: 0.9800\n",
      "Epoch 31/150\n",
      "150/150 [==============================] - 0s 695us/step - loss: 0.0453 - acc: 0.9933\n",
      "Epoch 32/150\n",
      "150/150 [==============================] - 0s 347us/step - loss: 0.0411 - acc: 0.9867\n",
      "Epoch 33/150\n",
      "150/150 [==============================] - 0s 678us/step - loss: 0.0420 - acc: 0.9867\n",
      "Epoch 34/150\n",
      "150/150 [==============================] - 0s 583us/step - loss: 0.0449 - acc: 0.9933\n",
      "Epoch 35/150\n",
      "150/150 [==============================] - 0s 460us/step - loss: 0.0449 - acc: 0.9867\n",
      "Epoch 36/150\n",
      "150/150 [==============================] - 0s 340us/step - loss: 0.0455 - acc: 0.9867\n",
      "Epoch 37/150\n",
      "150/150 [==============================] - 0s 887us/step - loss: 0.0515 - acc: 0.9800\n",
      "Epoch 38/150\n",
      "150/150 [==============================] - 0s 433us/step - loss: 0.0481 - acc: 0.9867\n",
      "Epoch 39/150\n",
      "150/150 [==============================] - 0s 350us/step - loss: 0.0402 - acc: 0.9933\n",
      "Epoch 40/150\n",
      "150/150 [==============================] - 0s 662us/step - loss: 0.0491 - acc: 0.9867\n",
      "Epoch 41/150\n",
      "150/150 [==============================] - 0s 317us/step - loss: 0.0412 - acc: 0.9933\n",
      "Epoch 42/150\n",
      "150/150 [==============================] - 0s 449us/step - loss: 0.0488 - acc: 0.9800\n",
      "Epoch 43/150\n",
      "150/150 [==============================] - 0s 549us/step - loss: 0.0453 - acc: 0.9867\n",
      "Epoch 44/150\n",
      "150/150 [==============================] - 0s 779us/step - loss: 0.0417 - acc: 0.9867\n",
      "Epoch 45/150\n",
      "150/150 [==============================] - 0s 285us/step - loss: 0.0407 - acc: 0.9867\n",
      "Epoch 46/150\n",
      "150/150 [==============================] - 0s 557us/step - loss: 0.0429 - acc: 0.9867\n",
      "Epoch 47/150\n",
      "150/150 [==============================] - 0s 902us/step - loss: 0.0434 - acc: 0.9867\n",
      "Epoch 48/150\n",
      "150/150 [==============================] - 0s 463us/step - loss: 0.0433 - acc: 0.9933\n",
      "Epoch 49/150\n",
      "150/150 [==============================] - 0s 389us/step - loss: 0.0434 - acc: 0.9933\n",
      "Epoch 50/150\n",
      "150/150 [==============================] - 0s 585us/step - loss: 0.0425 - acc: 0.9933\n",
      "Epoch 51/150\n",
      "150/150 [==============================] - 0s 715us/step - loss: 0.0457 - acc: 0.9867\n",
      "Epoch 52/150\n",
      "150/150 [==============================] - 0s 515us/step - loss: 0.0437 - acc: 0.9867\n",
      "Epoch 53/150\n",
      "150/150 [==============================] - 0s 543us/step - loss: 0.0436 - acc: 0.9800\n",
      "Epoch 54/150\n",
      "150/150 [==============================] - 0s 497us/step - loss: 0.0448 - acc: 0.9867\n",
      "Epoch 55/150\n",
      "150/150 [==============================] - 0s 375us/step - loss: 0.0483 - acc: 0.9867\n",
      "Epoch 56/150\n",
      "150/150 [==============================] - 0s 503us/step - loss: 0.0411 - acc: 0.9933\n",
      "Epoch 57/150\n",
      "150/150 [==============================] - 0s 261us/step - loss: 0.0447 - acc: 0.9867\n",
      "Epoch 58/150\n",
      "150/150 [==============================] - 0s 671us/step - loss: 0.0448 - acc: 0.9933\n",
      "Epoch 59/150\n",
      "150/150 [==============================] - 0s 838us/step - loss: 0.0418 - acc: 0.9867\n",
      "Epoch 60/150\n",
      "150/150 [==============================] - 0s 549us/step - loss: 0.0400 - acc: 0.9933\n",
      "Epoch 61/150\n",
      "150/150 [==============================] - 0s 252us/step - loss: 0.0485 - acc: 0.9867\n",
      "Epoch 62/150\n",
      "150/150 [==============================] - 0s 637us/step - loss: 0.0441 - acc: 0.9933\n",
      "Epoch 63/150\n",
      "150/150 [==============================] - 0s 623us/step - loss: 0.0440 - acc: 0.9867\n",
      "Epoch 64/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0431 - acc: 0.9867\n",
      "Epoch 65/150\n",
      "150/150 [==============================] - 0s 519us/step - loss: 0.0410 - acc: 0.9933\n",
      "Epoch 66/150\n",
      "150/150 [==============================] - 0s 388us/step - loss: 0.0421 - acc: 0.9933\n",
      "Epoch 67/150\n",
      "150/150 [==============================] - 0s 760us/step - loss: 0.0472 - acc: 0.9867\n",
      "Epoch 68/150\n",
      "150/150 [==============================] - 0s 596us/step - loss: 0.0421 - acc: 0.9933\n",
      "Epoch 69/150\n",
      "150/150 [==============================] - 0s 516us/step - loss: 0.0430 - acc: 0.9933\n",
      "Epoch 70/150\n",
      "150/150 [==============================] - 0s 420us/step - loss: 0.0419 - acc: 0.9933\n",
      "Epoch 71/150\n",
      "150/150 [==============================] - 0s 718us/step - loss: 0.0431 - acc: 0.9867\n",
      "Epoch 72/150\n",
      "150/150 [==============================] - 0s 672us/step - loss: 0.0437 - acc: 0.9867\n",
      "Epoch 73/150\n",
      "150/150 [==============================] - 0s 312us/step - loss: 0.0410 - acc: 0.9933\n",
      "Epoch 74/150\n",
      "150/150 [==============================] - 0s 572us/step - loss: 0.0458 - acc: 0.9867\n",
      "Epoch 75/150\n",
      "150/150 [==============================] - 0s 830us/step - loss: 0.0445 - acc: 0.9933\n",
      "Epoch 76/150\n",
      "150/150 [==============================] - 0s 855us/step - loss: 0.0395 - acc: 0.9933\n",
      "Epoch 77/150\n",
      "150/150 [==============================] - 0s 494us/step - loss: 0.0435 - acc: 0.9867\n",
      "Epoch 78/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0425 - acc: 0.9933\n",
      "Epoch 79/150\n",
      "150/150 [==============================] - 0s 586us/step - loss: 0.0406 - acc: 0.9933\n",
      "Epoch 80/150\n",
      "150/150 [==============================] - 0s 773us/step - loss: 0.0396 - acc: 0.9933\n",
      "Epoch 81/150\n",
      "150/150 [==============================] - 0s 377us/step - loss: 0.0459 - acc: 0.9800\n",
      "Epoch 82/150\n",
      "150/150 [==============================] - 0s 354us/step - loss: 0.0427 - acc: 0.9933\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 655us/step - loss: 0.0425 - acc: 0.9867\n",
      "Epoch 84/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0432 - acc: 0.9933\n",
      "Epoch 85/150\n",
      "150/150 [==============================] - 0s 420us/step - loss: 0.0477 - acc: 0.9867\n",
      "Epoch 86/150\n",
      "150/150 [==============================] - 0s 289us/step - loss: 0.0377 - acc: 0.9933\n",
      "Epoch 87/150\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.0477 - acc: 0.9867\n",
      "Epoch 88/150\n",
      "150/150 [==============================] - 0s 533us/step - loss: 0.0404 - acc: 0.9933\n",
      "Epoch 89/150\n",
      "150/150 [==============================] - 0s 555us/step - loss: 0.0427 - acc: 0.9933\n",
      "Epoch 90/150\n",
      "150/150 [==============================] - 0s 661us/step - loss: 0.0404 - acc: 0.9933\n",
      "Epoch 91/150\n",
      "150/150 [==============================] - 0s 518us/step - loss: 0.0451 - acc: 0.9867\n",
      "Epoch 92/150\n",
      "150/150 [==============================] - 0s 554us/step - loss: 0.0415 - acc: 0.9933\n",
      "Epoch 93/150\n",
      "150/150 [==============================] - 0s 381us/step - loss: 0.0447 - acc: 0.9933\n",
      "Epoch 94/150\n",
      "150/150 [==============================] - 0s 458us/step - loss: 0.0420 - acc: 0.9933\n",
      "Epoch 95/150\n",
      "150/150 [==============================] - 0s 634us/step - loss: 0.0441 - acc: 0.9933\n",
      "Epoch 96/150\n",
      "150/150 [==============================] - 0s 565us/step - loss: 0.0396 - acc: 0.9933\n",
      "Epoch 97/150\n",
      "150/150 [==============================] - 0s 642us/step - loss: 0.0462 - acc: 0.9867\n",
      "Epoch 98/150\n",
      "150/150 [==============================] - 0s 1ms/step - loss: 0.0421 - acc: 0.9933\n",
      "Epoch 99/150\n",
      "150/150 [==============================] - 0s 687us/step - loss: 0.0432 - acc: 0.9867\n",
      "Epoch 100/150\n",
      "150/150 [==============================] - 0s 521us/step - loss: 0.0423 - acc: 0.9867\n",
      "Epoch 101/150\n",
      "150/150 [==============================] - 0s 600us/step - loss: 0.0422 - acc: 0.9933\n",
      "Epoch 102/150\n",
      "150/150 [==============================] - 0s 649us/step - loss: 0.0408 - acc: 0.9933\n",
      "Epoch 103/150\n",
      "150/150 [==============================] - 0s 451us/step - loss: 0.0392 - acc: 0.9867\n",
      "Epoch 104/150\n",
      "150/150 [==============================] - 0s 614us/step - loss: 0.0408 - acc: 0.9867\n",
      "Epoch 105/150\n",
      "150/150 [==============================] - 0s 510us/step - loss: 0.0446 - acc: 0.9933\n",
      "Epoch 106/150\n",
      "150/150 [==============================] - 0s 582us/step - loss: 0.0422 - acc: 0.9933\n",
      "Epoch 107/150\n",
      "150/150 [==============================] - 0s 939us/step - loss: 0.0439 - acc: 0.9867\n",
      "Epoch 108/150\n",
      "150/150 [==============================] - 0s 370us/step - loss: 0.0395 - acc: 0.9867\n",
      "Epoch 109/150\n",
      "150/150 [==============================] - 0s 869us/step - loss: 0.0410 - acc: 0.9933\n",
      "Epoch 110/150\n",
      "150/150 [==============================] - 0s 560us/step - loss: 0.0409 - acc: 0.9933\n",
      "Epoch 111/150\n",
      "150/150 [==============================] - 0s 312us/step - loss: 0.0428 - acc: 0.9933\n",
      "Epoch 112/150\n",
      "150/150 [==============================] - 0s 592us/step - loss: 0.0430 - acc: 0.9933\n",
      "Epoch 113/150\n",
      "150/150 [==============================] - 0s 446us/step - loss: 0.0398 - acc: 0.9867\n",
      "Epoch 114/150\n",
      "150/150 [==============================] - 0s 437us/step - loss: 0.0486 - acc: 0.9733\n",
      "Epoch 115/150\n",
      "150/150 [==============================] - 0s 727us/step - loss: 0.0399 - acc: 0.9933\n",
      "Epoch 116/150\n",
      "150/150 [==============================] - 0s 448us/step - loss: 0.0466 - acc: 0.9800\n",
      "Epoch 117/150\n",
      "150/150 [==============================] - 0s 421us/step - loss: 0.0405 - acc: 0.9933\n",
      "Epoch 118/150\n",
      "150/150 [==============================] - 0s 652us/step - loss: 0.0418 - acc: 0.9867\n",
      "Epoch 119/150\n",
      "150/150 [==============================] - 0s 405us/step - loss: 0.0412 - acc: 0.9867\n",
      "Epoch 120/150\n",
      "150/150 [==============================] - 0s 468us/step - loss: 0.0396 - acc: 0.9867\n",
      "Epoch 121/150\n",
      "150/150 [==============================] - 0s 336us/step - loss: 0.0442 - acc: 0.9933\n",
      "Epoch 122/150\n",
      "150/150 [==============================] - 0s 531us/step - loss: 0.0403 - acc: 0.9867\n",
      "Epoch 123/150\n",
      "150/150 [==============================] - 0s 634us/step - loss: 0.0410 - acc: 0.9933\n",
      "Epoch 124/150\n",
      "150/150 [==============================] - 0s 414us/step - loss: 0.0409 - acc: 0.9867\n",
      "Epoch 125/150\n",
      "150/150 [==============================] - 0s 355us/step - loss: 0.0421 - acc: 0.9867\n",
      "Epoch 126/150\n",
      "150/150 [==============================] - 0s 403us/step - loss: 0.0431 - acc: 0.9933\n",
      "Epoch 127/150\n",
      "150/150 [==============================] - 0s 388us/step - loss: 0.0413 - acc: 0.9933\n",
      "Epoch 128/150\n",
      "150/150 [==============================] - 0s 362us/step - loss: 0.0435 - acc: 0.9933\n",
      "Epoch 129/150\n",
      "150/150 [==============================] - 0s 846us/step - loss: 0.0421 - acc: 0.9933\n",
      "Epoch 130/150\n",
      "150/150 [==============================] - 0s 327us/step - loss: 0.0413 - acc: 0.9933\n",
      "Epoch 131/150\n",
      "150/150 [==============================] - 0s 466us/step - loss: 0.0419 - acc: 0.9933\n",
      "Epoch 132/150\n",
      "150/150 [==============================] - 0s 309us/step - loss: 0.0427 - acc: 0.9867\n",
      "Epoch 133/150\n",
      "150/150 [==============================] - 0s 573us/step - loss: 0.0424 - acc: 0.9933\n",
      "Epoch 134/150\n",
      "150/150 [==============================] - 0s 446us/step - loss: 0.0424 - acc: 0.9933\n",
      "Epoch 135/150\n",
      "150/150 [==============================] - 0s 416us/step - loss: 0.0479 - acc: 0.9800\n",
      "Epoch 136/150\n",
      "150/150 [==============================] - 0s 291us/step - loss: 0.0402 - acc: 0.9933\n",
      "Epoch 137/150\n",
      "150/150 [==============================] - 0s 635us/step - loss: 0.0405 - acc: 0.9867\n",
      "Epoch 138/150\n",
      "150/150 [==============================] - 0s 330us/step - loss: 0.0436 - acc: 0.9933\n",
      "Epoch 139/150\n",
      "150/150 [==============================] - 0s 280us/step - loss: 0.0413 - acc: 0.9933\n",
      "Epoch 140/150\n",
      "150/150 [==============================] - 0s 369us/step - loss: 0.0419 - acc: 0.9933\n",
      "Epoch 141/150\n",
      "150/150 [==============================] - 0s 354us/step - loss: 0.0456 - acc: 0.9933\n",
      "Epoch 142/150\n",
      "150/150 [==============================] - 0s 321us/step - loss: 0.0419 - acc: 0.9933\n",
      "Epoch 143/150\n",
      "150/150 [==============================] - 0s 606us/step - loss: 0.0369 - acc: 0.9933\n",
      "Epoch 144/150\n",
      "150/150 [==============================] - 0s 666us/step - loss: 0.0434 - acc: 0.9867\n",
      "Epoch 145/150\n",
      "150/150 [==============================] - 0s 537us/step - loss: 0.0440 - acc: 0.9933 0s - loss: 0.0238 - acc: 1.000\n",
      "Epoch 146/150\n",
      "150/150 [==============================] - 0s 332us/step - loss: 0.0394 - acc: 0.9933\n",
      "Epoch 147/150\n",
      "150/150 [==============================] - 0s 453us/step - loss: 0.0421 - acc: 0.9867\n",
      "Epoch 148/150\n",
      "150/150 [==============================] - 0s 376us/step - loss: 0.0435 - acc: 0.9933\n",
      "Epoch 149/150\n",
      "150/150 [==============================] - 0s 635us/step - loss: 0.0396 - acc: 0.9933\n",
      "Epoch 150/150\n",
      "150/150 [==============================] - 0s 314us/step - loss: 0.0428 - acc: 0.9933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x181cbd7210>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 646us/step\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 99.33%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.82593715, -0.00901011,  0.28189826,  2.0211153 ,  1.3082693 ,\n",
       "          2.0267289 , -0.8302056 , -0.01896478,  1.7809083 ,  0.1887266 ],\n",
       "        [ 0.39858243, -0.5504208 , -0.40337482, -0.01459742, -1.8573946 ,\n",
       "         -1.050371  ,  1.2181045 , -0.5940317 ,  1.8763472 ,  2.067126  ],\n",
       "        [-1.1717069 ,  0.17620742, -0.53330684, -2.0294974 ,  1.52965   ,\n",
       "         -1.8089297 , -0.9556066 , -0.31293276, -1.2425474 , -1.1661578 ],\n",
       "        [ 0.23882145, -0.3564064 ,  0.1720898 , -1.5328745 ,  1.204789  ,\n",
       "         -0.55214965,  0.3255532 ,  2.043594  , -1.356086  , -0.9750487 ]],\n",
       "       dtype=float32),\n",
       " array([-0.02350465,  0.        ,  0.        ,  0.04585164, -0.04183529,\n",
       "         0.03139177,  0.        , -0.01695232,  0.05636105,  0.08017823],\n",
       "       dtype=float32),\n",
       " array([[ 1.1566594 , -0.9519539 , -0.3494704 ],\n",
       "        [-0.12331424, -0.08231172, -1.0616113 ],\n",
       "        [-0.68801665, -0.42752868,  0.13609926],\n",
       "        [ 1.7677438 ,  1.6786841 , -1.9242132 ],\n",
       "        [-1.9683312 ,  0.619738  ,  1.6524382 ],\n",
       "        [ 0.88800514,  2.0110815 , -1.9153696 ],\n",
       "        [ 0.6541419 ,  0.73385113,  1.5099758 ],\n",
       "        [-0.13644339, -1.9125819 ,  1.836685  ],\n",
       "        [ 1.4520254 , -0.0426807 , -1.4665418 ],\n",
       "        [ 1.319947  ,  2.0287464 , -2.033071  ]], dtype=float32),\n",
       " array([ 0.00084643,  0.0373447 , -0.03819113], dtype=float32)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
