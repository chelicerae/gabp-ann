{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width            class\n",
       "0           6.3          3.4           5.6          2.4   Iris-virginica\n",
       "1           7.7          3.0           6.1          2.3   Iris-virginica\n",
       "2           5.2          3.4           1.4          0.2      Iris-setosa\n",
       "3           5.1          3.8           1.5          0.3      Iris-setosa\n",
       "4           6.5          3.2           5.1          2.0   Iris-virginica\n",
       "5           6.6          3.0           4.4          1.4  Iris-versicolor\n",
       "6           7.2          3.2           6.0          1.8   Iris-virginica\n",
       "7           5.5          3.5           1.3          0.2      Iris-setosa\n",
       "8           5.0          3.0           1.6          0.2      Iris-setosa\n",
       "9           5.7          2.8           4.1          1.3  Iris-versicolor"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-0.144726</td>\n",
       "      <td>0.033182</td>\n",
       "      <td>-0.312850</td>\n",
       "      <td>-0.399467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-0.195359</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>-0.385314</td>\n",
       "      <td>-0.439467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.007173</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.194396</td>\n",
       "      <td>0.240533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.260338</td>\n",
       "      <td>0.169545</td>\n",
       "      <td>0.382802</td>\n",
       "      <td>0.320533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.043460</td>\n",
       "      <td>-0.148636</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>-0.039467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.083122</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.295845</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.235021</td>\n",
       "      <td>-0.057727</td>\n",
       "      <td>0.426280</td>\n",
       "      <td>0.320533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.171730</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.295845</td>\n",
       "      <td>0.160533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>-0.081435</td>\n",
       "      <td>-0.080455</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>0.080533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235021</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.339324</td>\n",
       "      <td>0.440533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  class\n",
       "79      -0.144726     0.033182     -0.312850    -0.399467      0\n",
       "58      -0.195359    -0.012273     -0.385314    -0.439467      0\n",
       "109      0.007173    -0.012273      0.194396     0.240533      2\n",
       "147      0.260338     0.169545      0.382802     0.320533      2\n",
       "24      -0.043460    -0.148636      0.005990    -0.039467      1\n",
       "98       0.083122    -0.012273      0.295845     0.400533      2\n",
       "95       0.235021    -0.057727      0.426280     0.320533      2\n",
       "128      0.171730    -0.012273      0.295845     0.160533      2\n",
       "122     -0.081435    -0.080455      0.020483     0.080533      1\n",
       "1        0.235021    -0.012273      0.339324     0.440533      2"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data standartization\n",
    "for label in list(dataset)[:-1]:\n",
    "    dataset[label] = (dataset[label] - dataset[label].mean()) / dataset[label].abs().max()\n",
    "\n",
    "# Mapping classes to numbers.\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "\n",
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing basic weights.\n",
    "\n",
    "all_weights = np.array([-1.47570343, -0.56032098,  1.75253888,  1.91032718,  1.49793612,\n",
    "        0.27734   ,  0.56471685,  0.0259936 ,  0.9611762 , -0.09302887,\n",
    "        1.22787263,  0.79945753,  1.04967658,  0.33256758,  1.32106727,\n",
    "        1.76057665,  0.62532468,  0.30350589, -0.38776123,  1.78441392,\n",
    "       -0.48050222,  1.78150069, -1.70355441, -1.88708973, -0.72664725,\n",
    "        0.1919236 , -1.25502323,  0.04139502,  0.79621135,  1.04941457,\n",
    "       -0.90026755, -1.43964992, -1.49593175,  0.74881736, -1.91076505,\n",
    "        0.15994606, -1.88483344, -0.12436311, -0.61805816, -1.98142732,\n",
    "        1.30450241, -1.46063758,  1.04332685,  1.77906528,  0.54554118,\n",
    "        0.71129359, -0.62701597, -0.54057435,  1.82995089,  1.49314732,\n",
    "       -1.89271037,  0.51417962, -0.85275575, -1.47914558, -0.6342658 ,\n",
    "        1.62675691, -0.57657448,  0.85276596,  1.83817083,  1.58471065,\n",
    "       -0.53742971,  0.0722263 ,  0.20491349, -1.24881042, -0.11687674,\n",
    "       -0.90906869,  0.07623699, -1.76395601, -1.74064463, -1.53866602,\n",
    "        1.89427938, -0.06510161,  1.86715126,  1.87329074,  1.2508516 ,\n",
    "       -0.67583785,  0.83771378, -1.27949391, -1.07428228, -0.51925524,\n",
    "        1.15731482, -1.71351281, -1.01585694])\n",
    "\n",
    "#  Reshaping 1D input weights to 2 2D matrix and bias vectors.\n",
    "theta1 = all_weights[:40]\n",
    "bias1 = all_weights[40:50]\n",
    "theta2 = all_weights[50:80]\n",
    "bias2 = all_weights[80:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step\n",
      "50/50 [==============================] - 0s 145us/step\n"
     ]
    }
   ],
   "source": [
    "model.set_weights([theta1.T, bias1, theta2.T, bias2])\n",
    "\n",
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 66.00%\n",
      "Test:\n",
      "acc: 68.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 2.1423 - acc: 0.6600\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 381us/step - loss: 1.7490 - acc: 0.6600\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 1.3978 - acc: 0.6600\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 408us/step - loss: 1.1107 - acc: 0.6600\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 274us/step - loss: 0.8824 - acc: 0.6600\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.7070 - acc: 0.6600\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.5657 - acc: 0.6700\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.4540 - acc: 0.7300\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 321us/step - loss: 0.3734 - acc: 0.7800\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.3153 - acc: 0.8800\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.2795 - acc: 0.9100\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 318us/step - loss: 0.2549 - acc: 0.9500\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 329us/step - loss: 0.2389 - acc: 0.9500\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 323us/step - loss: 0.2281 - acc: 0.9600\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 325us/step - loss: 0.2206 - acc: 0.9700\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.2151 - acc: 0.9700\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.2104 - acc: 0.9700\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.2063 - acc: 0.9600\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.2030 - acc: 0.9700\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.2011 - acc: 0.9500\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 323us/step - loss: 0.1972 - acc: 0.9500\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.1942 - acc: 0.9500\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.1913 - acc: 0.9500\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.1883 - acc: 0.9500\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 302us/step - loss: 0.1870 - acc: 0.9500\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.1847 - acc: 0.9600\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.1827 - acc: 0.9500\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.1815 - acc: 0.9500\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1794 - acc: 0.9500\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 322us/step - loss: 0.1776 - acc: 0.9500\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 292us/step - loss: 0.1769 - acc: 0.9500\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 302us/step - loss: 0.1757 - acc: 0.9500\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.1743 - acc: 0.9500\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.1728 - acc: 0.9600\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 257us/step - loss: 0.1727 - acc: 0.9500\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.1714 - acc: 0.9500\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 302us/step - loss: 0.1704 - acc: 0.9500\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 291us/step - loss: 0.1699 - acc: 0.9500\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 308us/step - loss: 0.1688 - acc: 0.9500\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.1678 - acc: 0.9500\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.1667 - acc: 0.9500\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1665 - acc: 0.9500\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.1661 - acc: 0.9600\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1649 - acc: 0.9500\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.1640 - acc: 0.9500\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.1639 - acc: 0.9500\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.1625 - acc: 0.9500\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 406us/step - loss: 0.1623 - acc: 0.9500\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.1615 - acc: 0.9500\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 286us/step - loss: 0.1608 - acc: 0.9500\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 303us/step - loss: 0.1605 - acc: 0.9500\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 306us/step - loss: 0.1597 - acc: 0.9600\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1594 - acc: 0.9500\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.1583 - acc: 0.9600\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.1578 - acc: 0.9600\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.1569 - acc: 0.9600\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.1575 - acc: 0.9500\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.1561 - acc: 0.9500\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 275us/step - loss: 0.1559 - acc: 0.9500\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 274us/step - loss: 0.1553 - acc: 0.9500\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1550 - acc: 0.9500\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 429us/step - loss: 0.1547 - acc: 0.9500\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.1535 - acc: 0.9600\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 254us/step - loss: 0.1531 - acc: 0.9500\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 292us/step - loss: 0.1530 - acc: 0.9600\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 308us/step - loss: 0.1522 - acc: 0.9500\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.1516 - acc: 0.9500\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 303us/step - loss: 0.1517 - acc: 0.9500\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.1508 - acc: 0.9500\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 364us/step - loss: 0.1503 - acc: 0.9500\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.1503 - acc: 0.9500\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.1500 - acc: 0.9600\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.1491 - acc: 0.9500\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 254us/step - loss: 0.1490 - acc: 0.9500\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.1483 - acc: 0.9500\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.1476 - acc: 0.9600\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 271us/step - loss: 0.1476 - acc: 0.9500\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 265us/step - loss: 0.1466 - acc: 0.9500\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.1468 - acc: 0.9500\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.1474 - acc: 0.9400\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.1458 - acc: 0.9500\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 272us/step - loss: 0.1464 - acc: 0.9500\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 324us/step - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.1452 - acc: 0.9500\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 293us/step - loss: 0.1443 - acc: 0.9500\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 384us/step - loss: 0.1436 - acc: 0.9500\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.1434 - acc: 0.9500\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.1438 - acc: 0.9500\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.1436 - acc: 0.9400\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.1421 - acc: 0.9500\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 250us/step - loss: 0.1421 - acc: 0.9500\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 266us/step - loss: 0.1421 - acc: 0.9500\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.1414 - acc: 0.9500\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 297us/step - loss: 0.1413 - acc: 0.9500\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 375us/step - loss: 0.1401 - acc: 0.9500\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 233us/step - loss: 0.1403 - acc: 0.9500\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 510us/step - loss: 0.1399 - acc: 0.9500\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.1391 - acc: 0.9500\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 253us/step - loss: 0.1389 - acc: 0.9500\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 293us/step - loss: 0.1385 - acc: 0.9500\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.1383 - acc: 0.9500\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.1374 - acc: 0.9500\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.1373 - acc: 0.9500\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.1369 - acc: 0.9500\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 301us/step - loss: 0.1367 - acc: 0.9500\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.1360 - acc: 0.9500\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 241us/step - loss: 0.1357 - acc: 0.9500\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 269us/step - loss: 0.1352 - acc: 0.9500\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 328us/step - loss: 0.1353 - acc: 0.9500\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 446us/step - loss: 0.1348 - acc: 0.9500\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 238us/step - loss: 0.1342 - acc: 0.9500\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.1341 - acc: 0.9500\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 283us/step - loss: 0.1337 - acc: 0.9500\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 448us/step - loss: 0.1332 - acc: 0.9500\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.1334 - acc: 0.9500\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 258us/step - loss: 0.1328 - acc: 0.9500\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.1325 - acc: 0.9500\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 244us/step - loss: 0.1317 - acc: 0.9500\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.1313 - acc: 0.9500\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.1312 - acc: 0.9500\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.1307 - acc: 0.9500\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 265us/step - loss: 0.1311 - acc: 0.9500\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.1302 - acc: 0.9500\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 266us/step - loss: 0.1298 - acc: 0.9500\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.1300 - acc: 0.9500\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.1295 - acc: 0.9500\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.1290 - acc: 0.9500\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.1291 - acc: 0.9400\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.1285 - acc: 0.9500\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 242us/step - loss: 0.1281 - acc: 0.9500\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1277 - acc: 0.9500\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 246us/step - loss: 0.1280 - acc: 0.9500\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.1274 - acc: 0.9500\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 244us/step - loss: 0.1276 - acc: 0.9500\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 286us/step - loss: 0.1270 - acc: 0.9500\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.1265 - acc: 0.9500\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 327us/step - loss: 0.1269 - acc: 0.9500\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1263 - acc: 0.9500\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.1263 - acc: 0.9500\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.1256 - acc: 0.9500\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 265us/step - loss: 0.1257 - acc: 0.9500\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 278us/step - loss: 0.1261 - acc: 0.9500\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.1248 - acc: 0.9500\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 258us/step - loss: 0.1256 - acc: 0.9500\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 362us/step - loss: 0.1245 - acc: 0.9500\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 300us/step - loss: 0.1245 - acc: 0.9500\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 302us/step - loss: 0.1238 - acc: 0.9500\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 317us/step - loss: 0.1239 - acc: 0.9500\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 271us/step - loss: 0.1235 - acc: 0.9500\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 317us/step - loss: 0.1234 - acc: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x182228db10>"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 125us/step\n",
      "50/50 [==============================] - 0s 251us/step\n"
     ]
    }
   ],
   "source": [
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 95.00%\n",
      "Test:\n",
      "acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.12129605,  1.1414499 ,  1.8287032 ,  1.197967  , -0.23940828,\n",
       "          1.5388327 , -2.0305076 , -1.2679032 , -1.3921349 ,  1.2141073 ],\n",
       "        [-1.528534  ,  1.2004582 ,  1.132461  , -0.9021921 ,  0.12258842,\n",
       "         -1.7715137 ,  1.9272462 ,  0.7180337 , -1.5698389 ,  1.557972  ],\n",
       "        [ 0.1908095 , -2.1938727 , -1.9225051 ,  0.18214469,  0.5943558 ,\n",
       "          2.061206  ,  1.0078062 ,  0.0305413 , -0.8459417 , -1.7095819 ],\n",
       "        [-0.24911903, -1.6868356 , -0.29562044, -1.9896674 ,  0.9614039 ,\n",
       "          2.1186361 , -0.11543606, -0.45685276, -1.1881891 , -2.0133252 ]],\n",
       "       dtype=float32),\n",
       " array([-0.4369997 ,  0.83060896, -1.125353  ,  0.6968958 , -1.2465042 ,\n",
       "         0.4252797 , -0.06002772, -0.6161836 ,  0.10193942,  0.90474343],\n",
       "       dtype=float32),\n",
       " array([[-1.9974568 , -1.1079164 ,  0.74428606],\n",
       "        [ 1.3465135 , -0.78044224, -1.7003281 ],\n",
       "        [ 1.3785197 ,  0.71266013,  1.9570906 ],\n",
       "        [ 0.7566066 ,  1.8074772 , -1.8238305 ],\n",
       "        [ 0.64990187, -0.5158149 ,  0.97621155],\n",
       "        [-1.9250046 , -0.87008476,  2.367424  ],\n",
       "        [-0.05205862,  1.3140781 , -1.7909278 ],\n",
       "        [ 1.7291831 , -0.9945487 , -1.265376  ],\n",
       "        [ 0.87581617,  0.35152644, -1.0939636 ],\n",
       "        [ 1.7039464 ,  0.46797618, -1.7524608 ]], dtype=float32),\n",
       " array([-1.8978047,  1.3257744, -0.3753495], dtype=float32)]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
