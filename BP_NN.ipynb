{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width  class\n",
       "0           6.8          3.0           5.5          2.1      2\n",
       "1           6.3          2.9           5.6          1.8      2\n",
       "2           5.7          2.8           4.5          1.3      1\n",
       "3           5.6          2.8           4.9          2.0      2\n",
       "4           6.2          2.8           4.8          1.8      2\n",
       "5           5.8          2.6           4.0          1.2      1\n",
       "6           6.5          3.0           5.8          2.2      2\n",
       "7           7.7          3.0           6.1          2.3      2\n",
       "8           6.3          3.3           4.7          1.6      1\n",
       "9           5.4          3.7           1.5          0.2      0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No bias results 50 000 iterations (-2, 2)\n",
    "\n",
    "# all_weights = np.array([ 0.82850905,  0.40072448, -1.16062222,  0.24129967, -0.00901011,\n",
    "#        -0.55042084,  0.17620743, -0.35640638,  0.28189825, -0.40337483,\n",
    "#        -0.53330681,  0.1720898 ,  1.99998587, -0.0237903 , -1.99372395,\n",
    "#        -1.53997806,  1.31316753, -1.85079916,  1.53083946,  1.20376128,\n",
    "#         2.        , -1.03966506, -1.78537761, -0.57303334, -0.83020559,\n",
    "#         1.2181045 , -0.95560658,  0.32555322, -0.01306465, -0.58740851,\n",
    "#        -0.30109983,  2.        ,  1.7863003 ,  1.87352263, -1.2398616 ,\n",
    "#        -1.35349408,  0.21784511,  2.        , -1.14411966, -0.96291608,\n",
    "#         1.15340453, -0.12331424, -0.68801667,  1.76125887, -1.96991071,\n",
    "#         0.88347918,  0.65414193, -0.13644339,  1.44238258,  1.31562074,\n",
    "#        -0.95010176, -0.08231172, -0.42752867,  1.66501362,  0.62532375,\n",
    "#         1.99714638,  0.73385111, -1.89800158, -0.01269442,  2.        ,\n",
    "#        -0.34806914, -1.06161126,  0.13609927, -1.90406267,  1.64843287,\n",
    "#        -1.89691344,  1.50997576,  1.82210462, -1.48688357, -2.        ])\n",
    "\n",
    "# Bias results 1000 iterations (-100, 100)\n",
    "\n",
    "# all_weights = np.array([-55.99912628,  -2.94074698,  48.62230211,  27.70564858,\n",
    "#        -14.72015624,  -9.42324088, -43.03292206, -18.40727773,\n",
    "#        -43.64839552, -58.04569456, -50.20950896, -85.52187718,\n",
    "#         70.56984522,   5.20257721,  -0.26611847,  83.19208242,\n",
    "#        -72.17945228,  49.45460294,  -2.2190893 ,   4.7459282 ,\n",
    "#        -83.69299758,  58.1335316 , -15.73228806, -34.88828344,\n",
    "#         78.57904655,  68.61037977,  13.15403183,  89.08639842,\n",
    "#         36.90008999, -43.38496429,  93.1164013 ,  10.73194315,\n",
    "#         93.14897671, -50.62290616,   8.02729018,  96.21904633,\n",
    "#         17.4439362 ,  25.44069502,  68.22808982,  -7.54487909,\n",
    "#        -99.80341536, -64.52404744,  42.77614549, -76.405061  ,\n",
    "#        -72.08232071,  14.85601168, -53.68871622,  36.09791257,\n",
    "#        -22.96207116,  71.75095558,  84.62201604, -66.19849963,\n",
    "#        -89.07164706,  65.08517806, -42.65904316,  61.44426617,\n",
    "#         28.48123545, -11.79782272,  33.36877307,  73.80732532,\n",
    "#        -97.63618378,  63.64767343, -59.50050103, -82.1135804 ,\n",
    "#         77.1921181 , -49.07060001, -83.14296263,  20.58923936,\n",
    "#         22.45407113, -60.34021219,  93.07392893,  66.8388894 ,\n",
    "#        -53.42301689, -64.53013567,  34.68704473,  40.19995135,\n",
    "#        -20.92426576,  -6.45971336, -27.03420895,  -5.00038901,\n",
    "#        -65.3913821 , -31.87113074,  43.80992814])\n",
    "\n",
    "# Bias results 1000 iterations (-2, 2)\n",
    "\n",
    "# all_weights = np.array([ 0.44539658, -0.54400259,  0.4147466 ,  1.1843882 ,  1.55279398,\n",
    "#         0.46813689, -1.32291181, -1.99987314, -0.49823897,  1.3223775 ,\n",
    "#         0.51995836,  0.86037499, -1.60616985, -1.24742032,  0.12282469,\n",
    "#         0.79423939,  0.95008809,  1.69781401, -1.91294032, -1.82596235,\n",
    "#        -0.2203242 , -1.23333196, -0.11080954, -0.69195492,  0.16182995,\n",
    "#        -0.70553753,  1.87664087,  0.23026903,  0.7471049 , -1.7373532 ,\n",
    "#         1.36182834, -0.5408667 , -0.94710073, -0.23820658, -0.69248999,\n",
    "#         0.57001043, -0.33089435,  0.22820795,  1.8313249 , -0.35236008,\n",
    "#         0.30297719,  1.93726387,  0.92641075, -0.62700894,  1.82442043,\n",
    "#        -1.01640387, -1.99864327, -0.06462852, -1.53881716,  0.48566329,\n",
    "#        -1.64920395,  1.99999965,  1.75121857,  0.52660668,  1.21734099,\n",
    "#        -0.45846083, -1.32921847, -1.4606413 ,  0.93423697, -0.86710597,\n",
    "#        -1.13187115,  0.29267539,  0.10607832,  1.1551053 ,  1.76731577,\n",
    "#         0.31406486,  0.76772426,  0.69169783, -0.83668658,  0.33569889,\n",
    "#         0.64205243, -1.98684006,  0.19627804,  0.63516307, -2.        ,\n",
    "#         0.19437876,  1.83094245,  0.1938955 ,  1.2000416 , -0.27878783,\n",
    "#         1.3122472 ,  0.7280207 , -1.34736464])\n",
    "\n",
    "# Bias results (-2, 2) 1000 iterations \n",
    "\n",
    "# all_weights = np.array([-0.12129605, -1.52853405,  0.19080951, -0.24911903,  1.26105855,\n",
    "#         1.03348761, -1.74095598, -1.16912224,  1.82870315,  1.13246097,\n",
    "#        -1.92250512, -0.29562043,  1.272132  , -0.88395889,  0.41502269,\n",
    "#        -1.62145995, -0.23940828,  0.12258842,  0.5943558 ,  0.96140391,\n",
    "#         1.43295031, -1.69399583,  1.67231008,  1.58961642, -1.99320226,\n",
    "#         1.92954028,  1.13961794,  0.12091686, -1.26790324,  0.71803368,\n",
    "#         0.0305413 , -0.45685277, -1.39528121, -1.61745956, -0.77749755,\n",
    "#        -1.11405011,  1.32369548,  1.48570256, -1.38574018, -1.6245386 ,\n",
    "#        -0.43699971,  2.        , -1.12535292,  1.69962718, -1.24650415,\n",
    "#        -1.20377956,  1.1610347 , -0.61618357,  0.2382405 ,  1.6396031 ,\n",
    "#        -1.99745678,  1.10535453,  1.37851962,  0.74019612,  0.64990188,\n",
    "#        -1.6639427 , -0.08798229,  1.72918302,  0.70704046,  1.31502347,\n",
    "#        -1.10791639, -0.23961386,  0.71266012,  2.        , -0.51581491,\n",
    "#        -0.76351852,  1.5590716 , -0.99454865,  0.53418471,  0.89040827,\n",
    "#         0.74428609, -2.        ,  1.95709056, -1.99993718,  0.97621155,\n",
    "#         1.99979467, -2.        , -1.26537603, -1.10784762, -1.78597337,\n",
    "#        -1.5542085 ,  1.47093082, -0.86410135])\n",
    "\n",
    "# Bias and batch=10 10 000 iterations \n",
    "\n",
    "all_weights = np.array([ 1.30848932,  0.81764324,  1.80799548,  0.34838307, -0.07685203,\n",
    "        1.67280683, -0.86301839, -1.0747434 ,  1.79727309, -0.71171146,\n",
    "       -0.01800825, -1.16365216, -1.95096072,  0.62491266,  0.05381063,\n",
    "        1.71313736, -0.39757288, -0.16410246,  1.90997168,  1.96311439,\n",
    "       -1.3600024 , -1.30905888, -0.93432226,  1.01873819,  0.49787334,\n",
    "       -0.97811568, -1.27805269,  1.76423449,  0.73181911,  0.0686799 ,\n",
    "        1.25301359, -1.34329424,  0.38809433, -1.8002075 , -0.88237253,\n",
    "        0.4462813 , -0.45414581,  1.50860079,  1.64726395,  1.59883219,\n",
    "        1.33293314,  0.74163364,  0.59915971, -0.71005133, -0.1129822 ,\n",
    "        1.35726647, -1.35842979,  0.40672924, -0.250284  ,  0.30929123,\n",
    "       -1.46753851,  0.17188682,  0.81539141,  0.18308485, -1.29143111,\n",
    "        1.35951747,  0.43201388, -0.9777995 , -1.04724225, -1.3436225 ,\n",
    "       -0.13290859,  1.71373924, -1.66564308,  0.91921875,  0.06461448,\n",
    "        0.43124176,  0.33629514, -1.24159101,  1.60238144, -0.04673199,\n",
    "        0.46919664,  0.60200841,  0.9215234 , -1.12965767,  0.57210215,\n",
    "        0.62441395, -0.65487776,  1.99847449, -0.09075696,  0.17961145,\n",
    "        0.76963415, -0.41160485,  0.16902859])\n",
    "\n",
    "# theta1 = all_weights[:40]\n",
    "# theta2 = all_weights[40:]\n",
    "# theta1 = theta1.reshape((10, 4))\n",
    "# theta2 = theta2.reshape((3, 10))\n",
    "\n",
    "theta1 = all_weights[:40]\n",
    "bias1 = all_weights[40:50]\n",
    "theta2 = all_weights[50:80]\n",
    "bias2 = all_weights[80:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.set_weights([theta1.T, bias1, theta2.T, bias2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.1046 - acc: 0.9800\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.1149 - acc: 0.9600\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 321us/step - loss: 0.1048 - acc: 0.9700\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 293us/step - loss: 0.1152 - acc: 0.9600\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 295us/step - loss: 0.1045 - acc: 0.9700\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.1045 - acc: 0.9700\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.1126 - acc: 0.9600\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 317us/step - loss: 0.1083 - acc: 0.9700\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.1078 - acc: 0.9700\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 283us/step - loss: 0.1103 - acc: 0.9800\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 283us/step - loss: 0.1025 - acc: 0.9500\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.1056 - acc: 0.9800\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.1078 - acc: 0.9600\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 359us/step - loss: 0.1074 - acc: 0.9700\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.1089 - acc: 0.9700\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.1174 - acc: 0.9400\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.1116 - acc: 0.9700\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1013 - acc: 0.9800\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 533us/step - loss: 0.1053 - acc: 0.9700\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 0.1252 - acc: 0.9600\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 624us/step - loss: 0.1067 - acc: 0.9700\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.1136 - acc: 0.9600\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 509us/step - loss: 0.1037 - acc: 0.9700\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 397us/step - loss: 0.0986 - acc: 0.9800\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.1095 - acc: 0.9600\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 293us/step - loss: 0.1042 - acc: 0.9700\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 335us/step - loss: 0.1022 - acc: 0.9700\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 414us/step - loss: 0.1059 - acc: 0.9700\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 245us/step - loss: 0.1075 - acc: 0.9500\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 310us/step - loss: 0.1053 - acc: 0.9700\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.1060 - acc: 0.9700\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 246us/step - loss: 0.1006 - acc: 0.9800\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1051 - acc: 0.9600\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 362us/step - loss: 0.0959 - acc: 0.9700\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.1136 - acc: 0.9600\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.1110 - acc: 0.9800\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 480us/step - loss: 0.1054 - acc: 0.9600\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 515us/step - loss: 0.1040 - acc: 0.9700\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.1147 - acc: 0.9500\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 504us/step - loss: 0.0975 - acc: 0.9700\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 548us/step - loss: 0.1031 - acc: 0.9800\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.0984 - acc: 0.9800\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.1037 - acc: 0.9800\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.1015 - acc: 0.9600\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 306us/step - loss: 0.1172 - acc: 0.9600\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 294us/step - loss: 0.1145 - acc: 0.9600\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 403us/step - loss: 0.1004 - acc: 0.9800\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 434us/step - loss: 0.1083 - acc: 0.9700\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.0972 - acc: 0.9700\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.1080 - acc: 0.9700\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 328us/step - loss: 0.0953 - acc: 0.9700\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0975 - acc: 0.9700\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 324us/step - loss: 0.0979 - acc: 0.9800\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 272us/step - loss: 0.0942 - acc: 0.9800\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1181 - acc: 0.9600\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.1068 - acc: 0.9700\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.0994 - acc: 0.9700\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.1024 - acc: 0.9600\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0957 - acc: 0.9700\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 342us/step - loss: 0.1167 - acc: 0.9500\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 259us/step - loss: 0.1012 - acc: 0.9600\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 302us/step - loss: 0.0994 - acc: 0.9700\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.0993 - acc: 0.9800\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 251us/step - loss: 0.1031 - acc: 0.9700\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.1094 - acc: 0.9600\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 228us/step - loss: 0.1020 - acc: 0.9800\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.1032 - acc: 0.9700\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 314us/step - loss: 0.0989 - acc: 0.9800\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 241us/step - loss: 0.0982 - acc: 0.9800\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0959 - acc: 0.9700\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.1009 - acc: 0.9600\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 291us/step - loss: 0.0969 - acc: 0.9800\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.1036 - acc: 0.9700\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.0922 - acc: 0.9800\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.0995 - acc: 0.9700\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.0977 - acc: 0.9800\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.0980 - acc: 0.9700\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 314us/step - loss: 0.0979 - acc: 0.9700\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 295us/step - loss: 0.1148 - acc: 0.9700\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 302us/step - loss: 0.0955 - acc: 0.9600\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.1058 - acc: 0.9500\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.1009 - acc: 0.9700\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 478us/step - loss: 0.0951 - acc: 0.9800\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 319us/step - loss: 0.1076 - acc: 0.9500\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 320us/step - loss: 0.0948 - acc: 0.9900\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 322us/step - loss: 0.0951 - acc: 0.9700\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.1018 - acc: 0.9700\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.1079 - acc: 0.9700\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 285us/step - loss: 0.1050 - acc: 0.9700\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 254us/step - loss: 0.1091 - acc: 0.9600\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 237us/step - loss: 0.0950 - acc: 0.9800\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.0966 - acc: 0.9800\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.1170 - acc: 0.9500\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 273us/step - loss: 0.0898 - acc: 0.9800\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 308us/step - loss: 0.1104 - acc: 0.9400\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 280us/step - loss: 0.0965 - acc: 0.9800\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 287us/step - loss: 0.0996 - acc: 0.9700\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 212us/step - loss: 0.0938 - acc: 0.9700\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 328us/step - loss: 0.1043 - acc: 0.9600\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 276us/step - loss: 0.1048 - acc: 0.9600\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 299us/step - loss: 0.1040 - acc: 0.9700\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0961 - acc: 0.9600\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 345us/step - loss: 0.0937 - acc: 0.9800\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 396us/step - loss: 0.0956 - acc: 0.9600\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0999 - acc: 0.9700\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.0940 - acc: 0.9600\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 254us/step - loss: 0.0952 - acc: 0.9700\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.1018 - acc: 0.9600\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.0931 - acc: 0.9800\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 271us/step - loss: 0.0907 - acc: 0.9800\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.0938 - acc: 0.9800\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 234us/step - loss: 0.1062 - acc: 0.9600\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.1063 - acc: 0.9300\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.0951 - acc: 0.9800\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.0935 - acc: 0.9700\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 277us/step - loss: 0.0995 - acc: 0.9700\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.0940 - acc: 0.9800\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 291us/step - loss: 0.0892 - acc: 0.9800\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 312us/step - loss: 0.0917 - acc: 0.9700\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1121 - acc: 0.9500\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 265us/step - loss: 0.0968 - acc: 0.9800\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 311us/step - loss: 0.0932 - acc: 0.9800\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.1025 - acc: 0.9700\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 255us/step - loss: 0.0946 - acc: 0.9700\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 300us/step - loss: 0.1074 - acc: 0.9400\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 244us/step - loss: 0.1025 - acc: 0.9700\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0892 - acc: 0.9700\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0986 - acc: 0.9600\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.1021 - acc: 0.9700\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.0876 - acc: 0.9800\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.0897 - acc: 0.9600\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.0945 - acc: 0.9600\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.0984 - acc: 0.9700\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.0958 - acc: 0.9700\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 273us/step - loss: 0.1023 - acc: 0.9600\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.1094 - acc: 0.9500\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0907 - acc: 0.9800\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 277us/step - loss: 0.1038 - acc: 0.9300\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 318us/step - loss: 0.1128 - acc: 0.9600\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 256us/step - loss: 0.0969 - acc: 0.9800\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 286us/step - loss: 0.1032 - acc: 0.9600\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 228us/step - loss: 0.0926 - acc: 0.9800\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.0975 - acc: 0.9700\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 246us/step - loss: 0.0968 - acc: 0.9600\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 297us/step - loss: 0.1011 - acc: 0.9600\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0920 - acc: 0.9800\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0990 - acc: 0.9700\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 307us/step - loss: 0.0922 - acc: 0.9700\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 383us/step - loss: 0.0964 - acc: 0.9700\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 286us/step - loss: 0.0930 - acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18140bf810>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 97us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0756785372644662"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(X, y)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "acc: 99.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.37042946,  0.19364983, -0.61618567,  0.601436  ,  0.8987613 ,\n",
       "         -0.8320404 , -0.37514338,  0.48938337, -0.48200852, -0.1906842 ],\n",
       "        [ 0.6457862 , -0.29363513,  0.27914652,  0.16452809,  0.89903975,\n",
       "         -0.56741667,  0.60845816,  0.16432913,  0.16767907, -0.07367782],\n",
       "        [-0.8519115 , -0.11580761,  0.40092298,  0.5889215 , -1.2328597 ,\n",
       "          1.205422  , -0.52587855, -0.6657519 ,  0.3284272 ,  0.40771842],\n",
       "        [ 0.2972285 , -0.1375943 ,  0.2135342 ,  0.5145194 , -0.846137  ,\n",
       "          1.7315216 ,  0.05286014, -0.5603277 , -0.09211999, -0.6523648 ]],\n",
       "       dtype=float32),\n",
       " array([ 0.09228639, -0.00473215, -0.00650457,  0.01866557,  0.40406284,\n",
       "        -0.63435966,  0.        ,  0.06122282,  0.        , -0.01525889],\n",
       "       dtype=float32),\n",
       " array([[ 0.82665455, -0.00940004, -0.24794307],\n",
       "        [-0.29962906, -0.1715637 ,  0.5703985 ],\n",
       "        [ 0.4474163 ,  0.33320424, -0.33405593],\n",
       "        [-0.82800233,  0.41841108,  0.2703084 ],\n",
       "        [ 1.1477437 , -0.03400394, -1.602177  ],\n",
       "        [ 0.06948093, -1.3022715 ,  1.7240604 ],\n",
       "        [-0.4287253 , -0.59361726, -0.34948072],\n",
       "        [ 0.6440788 , -0.80599004,  0.24621917],\n",
       "        [-0.3105248 ,  0.4375702 , -0.5783126 ],\n",
       "        [-0.1690552 , -0.5762356 , -0.6521799 ]], dtype=float32),\n",
       " array([-0.01353172,  0.43096712, -0.4174349 ], dtype=float32)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
