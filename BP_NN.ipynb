{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width            class\n",
       "0           6.4          2.8           5.6          2.1   Iris-virginica\n",
       "1           5.2          2.7           3.9          1.4  Iris-versicolor\n",
       "2           4.8          3.0           1.4          0.3      Iris-setosa\n",
       "3           5.2          4.1           1.5          0.1      Iris-setosa\n",
       "4           4.6          3.1           1.5          0.2      Iris-setosa\n",
       "5           6.1          2.8           4.0          1.3  Iris-versicolor\n",
       "6           6.0          2.9           4.5          1.5  Iris-versicolor\n",
       "7           4.9          3.0           1.4          0.2      Iris-setosa\n",
       "8           7.7          2.8           6.7          2.0   Iris-virginica\n",
       "9           4.8          3.4           1.9          0.2      Iris-setosa"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.070464</td>\n",
       "      <td>-0.035000</td>\n",
       "      <td>0.078454</td>\n",
       "      <td>0.040533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.070464</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>0.252367</td>\n",
       "      <td>0.240533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.083122</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.252367</td>\n",
       "      <td>0.240533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>-0.106751</td>\n",
       "      <td>-0.171364</td>\n",
       "      <td>-0.066473</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>-0.132068</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>-0.341836</td>\n",
       "      <td>-0.439467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.081435</td>\n",
       "      <td>-0.080455</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>0.080533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.081435</td>\n",
       "      <td>0.237727</td>\n",
       "      <td>-0.327343</td>\n",
       "      <td>-0.439467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.121097</td>\n",
       "      <td>0.033182</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>0.440533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.095781</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.092947</td>\n",
       "      <td>0.080533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.032489</td>\n",
       "      <td>-0.103182</td>\n",
       "      <td>0.266860</td>\n",
       "      <td>0.080533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  class\n",
       "17       0.070464    -0.035000      0.078454     0.040533      1\n",
       "82       0.070464     0.010455      0.252367     0.240533      2\n",
       "117      0.083122    -0.012273      0.252367     0.240533      2\n",
       "69      -0.106751    -0.171364     -0.066473    -0.079467      1\n",
       "130     -0.132068    -0.012273     -0.341836    -0.439467      0\n",
       "1       -0.081435    -0.080455      0.020483     0.080533      1\n",
       "3       -0.081435     0.237727     -0.327343    -0.439467      0\n",
       "62       0.121097     0.033182      0.310338     0.440533      2\n",
       "39       0.095781    -0.012273      0.092947     0.080533      1\n",
       "136      0.032489    -0.103182      0.266860     0.080533      2"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data standartization\n",
    "for label in list(dataset)[:-1]:\n",
    "    dataset[label] = (dataset[label] - dataset[label].mean()) / dataset[label].abs().max()\n",
    "\n",
    "# Mapping classes to numbers.\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "\n",
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing basic weights.\n",
    "\n",
    "all_weights = np.array([-0.11956666,  1.60757496, -1.60115118, -0.01512596, -0.63268727,\n",
    "        0.04287272,  0.7845708 , -1.98334794,  0.05424702,  0.08041573,\n",
    "        1.86520092,  0.84061018,  0.19273817,  1.58142388, -1.18296091,\n",
    "       -0.36947794, -1.82491911, -1.3585935 ,  1.43440512,  1.25264398,\n",
    "       -1.87437234, -0.96126959, -0.19941367, -1.99482165,  1.60326499,\n",
    "       -1.10554801, -0.80067292, -0.03431882, -1.49743684,  1.74736905,\n",
    "       -1.43940704, -1.70685305,  0.81107803,  0.38819742,  1.6753215 ,\n",
    "        1.27688657,  0.13276105, -1.25716079,  1.67214695, -0.15582424,\n",
    "        0.87290021,  0.73139845,  1.21441429, -0.75315388, -1.16677647,\n",
    "       -0.5926008 , -1.08107115,  1.36668028,  1.96621121, -0.3339175 ,\n",
    "        1.86446984,  1.25271354, -1.02780653, -0.80520123, -0.44166891,\n",
    "        0.70027392, -0.76132972,  1.32227312, -0.8358854 , -0.04059621,\n",
    "       -1.46407095,  1.25734053,  0.66699922, -1.12802165, -1.03722805,\n",
    "        0.49884331, -1.80602096, -1.06096596, -1.50958309, -0.32203364,\n",
    "       -0.68736231,  0.01052929,  1.96004013, -1.46459389,  0.68320843,\n",
    "       -1.61925607,  0.26758798, -1.68382157,  1.9233228 ,  1.53693003,\n",
    "        1.30071251, -1.22386937, -0.42051178])\n",
    "\n",
    "#  Reshaping 1D input weights to 2 2D matrix and bias vectors.\n",
    "theta1 = all_weights[:40]\n",
    "bias1 = all_weights[40:50]\n",
    "theta2 = all_weights[50:80]\n",
    "bias2 = all_weights[80:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step\n",
      "50/50 [==============================] - 0s 153us/step\n"
     ]
    }
   ],
   "source": [
    "model.set_weights([theta1.T, bias1, theta2.T, bias2])\n",
    "\n",
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 71.00%\n",
      "Test:\n",
      "acc: 58.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 0s 306us/step - loss: 0.0996 - acc: 0.9800\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.0992 - acc: 0.9800\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 297us/step - loss: 0.0991 - acc: 0.9800\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0997 - acc: 0.9800\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.0987 - acc: 0.9800\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.0986 - acc: 0.9800\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0986 - acc: 0.9800\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0984 - acc: 0.9800\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 388us/step - loss: 0.0984 - acc: 0.9800\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0980 - acc: 0.9800\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 330us/step - loss: 0.0979 - acc: 0.9800\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 553us/step - loss: 0.0978 - acc: 0.9800\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 551us/step - loss: 0.0977 - acc: 0.9800\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 534us/step - loss: 0.0977 - acc: 0.9800\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 665us/step - loss: 0.0974 - acc: 0.9800\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 410us/step - loss: 0.0975 - acc: 0.9800\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 550us/step - loss: 0.0973 - acc: 0.9800\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 962us/step - loss: 0.0975 - acc: 0.9700\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 818us/step - loss: 0.0967 - acc: 0.9800\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 798us/step - loss: 0.0968 - acc: 0.9800\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 879us/step - loss: 0.0965 - acc: 0.9800\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.0969 - acc: 0.9800\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.0965 - acc: 0.9800\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.0962 - acc: 0.9800\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 452us/step - loss: 0.0960 - acc: 0.9800\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.0962 - acc: 0.9800\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 394us/step - loss: 0.0960 - acc: 0.9800\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 384us/step - loss: 0.0958 - acc: 0.9800\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.0960 - acc: 0.9800\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.0956 - acc: 0.9800\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 411us/step - loss: 0.0953 - acc: 0.9800\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 354us/step - loss: 0.0951 - acc: 0.9800\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 378us/step - loss: 0.0954 - acc: 0.9800\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 425us/step - loss: 0.0952 - acc: 0.9800\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.0950 - acc: 0.9800\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 402us/step - loss: 0.0950 - acc: 0.9800\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.0950 - acc: 0.9800\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.0944 - acc: 0.9800\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 875us/step - loss: 0.0944 - acc: 0.9800\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 521us/step - loss: 0.0944 - acc: 0.9800\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.0943 - acc: 0.9800\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 776us/step - loss: 0.0940 - acc: 0.9800\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 498us/step - loss: 0.0939 - acc: 0.9800\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 399us/step - loss: 0.0940 - acc: 0.9800\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0940 - acc: 0.9800\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 519us/step - loss: 0.0939 - acc: 0.9700\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0934 - acc: 0.9800\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 391us/step - loss: 0.0934 - acc: 0.9800\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.0936 - acc: 0.9800\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.0931 - acc: 0.9800\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0932 - acc: 0.9800\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 406us/step - loss: 0.0929 - acc: 0.9800\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 448us/step - loss: 0.0927 - acc: 0.9800\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 384us/step - loss: 0.0925 - acc: 0.9800\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0924 - acc: 0.9800\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 349us/step - loss: 0.0927 - acc: 0.9800\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.0923 - acc: 0.9800\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 317us/step - loss: 0.0923 - acc: 0.9800\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.0925 - acc: 0.9800\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 430us/step - loss: 0.0920 - acc: 0.9800\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 347us/step - loss: 0.0918 - acc: 0.9800\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 389us/step - loss: 0.0917 - acc: 0.9800\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 498us/step - loss: 0.0914 - acc: 0.9800\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 630us/step - loss: 0.0916 - acc: 0.9800\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.0914 - acc: 0.9800\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.0911 - acc: 0.9800\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 426us/step - loss: 0.0911 - acc: 0.9800\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 557us/step - loss: 0.0910 - acc: 0.9800\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 392us/step - loss: 0.0910 - acc: 0.9800\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 400us/step - loss: 0.0910 - acc: 0.9800\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 379us/step - loss: 0.0909 - acc: 0.9800\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.0906 - acc: 0.9800\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.0910 - acc: 0.9700\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 371us/step - loss: 0.0903 - acc: 0.9800\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.0904 - acc: 0.9800\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0904 - acc: 0.9800\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 346us/step - loss: 0.0900 - acc: 0.9800\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.0903 - acc: 0.9800\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.0900 - acc: 0.9800\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.0899 - acc: 0.9800\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 314us/step - loss: 0.0899 - acc: 0.9800\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.0898 - acc: 0.9700\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 321us/step - loss: 0.0897 - acc: 0.9800\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 301us/step - loss: 0.0893 - acc: 0.9800\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.0892 - acc: 0.9800\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.0891 - acc: 0.9800\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.0894 - acc: 0.9800\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 303us/step - loss: 0.0888 - acc: 0.9800\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 273us/step - loss: 0.0889 - acc: 0.9800\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 413us/step - loss: 0.0891 - acc: 0.9800\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 285us/step - loss: 0.0885 - acc: 0.9800\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.0887 - acc: 0.9800\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.0884 - acc: 0.9800\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 363us/step - loss: 0.0886 - acc: 0.9700\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 245us/step - loss: 0.0885 - acc: 0.9800\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0882 - acc: 0.9800\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.0881 - acc: 0.9800\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0879 - acc: 0.9700\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 432us/step - loss: 0.0880 - acc: 0.9800\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 276us/step - loss: 0.0880 - acc: 0.9800\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 427us/step - loss: 0.0883 - acc: 0.9700\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 270us/step - loss: 0.0880 - acc: 0.9700\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 373us/step - loss: 0.0876 - acc: 0.9800\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 239us/step - loss: 0.0878 - acc: 0.9800\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 347us/step - loss: 0.0875 - acc: 0.9800\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 273us/step - loss: 0.0874 - acc: 0.9800\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.0874 - acc: 0.9800\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 274us/step - loss: 0.0875 - acc: 0.9700\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 268us/step - loss: 0.0870 - acc: 0.9800\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 321us/step - loss: 0.0874 - acc: 0.9800\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 398us/step - loss: 0.0872 - acc: 0.9800\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 266us/step - loss: 0.0868 - acc: 0.9700\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 243us/step - loss: 0.0864 - acc: 0.9800\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.0867 - acc: 0.9800\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 361us/step - loss: 0.0866 - acc: 0.9700\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 228us/step - loss: 0.0864 - acc: 0.9800\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.0863 - acc: 0.9800\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.0862 - acc: 0.9800\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.0859 - acc: 0.9800\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 272us/step - loss: 0.0859 - acc: 0.9700\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 305us/step - loss: 0.0859 - acc: 0.9800\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.0858 - acc: 0.9800\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 366us/step - loss: 0.0860 - acc: 0.9800\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 275us/step - loss: 0.0855 - acc: 0.9800\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.0857 - acc: 0.9800\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.0856 - acc: 0.9800\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 286us/step - loss: 0.0854 - acc: 0.9800\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.0853 - acc: 0.9800\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 282us/step - loss: 0.0855 - acc: 0.9800\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 355us/step - loss: 0.0849 - acc: 0.9700\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 285us/step - loss: 0.0849 - acc: 0.9800\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 283us/step - loss: 0.0850 - acc: 0.9800\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 409us/step - loss: 0.0850 - acc: 0.9700\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 263us/step - loss: 0.0848 - acc: 0.9800\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 309us/step - loss: 0.0846 - acc: 0.9800\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 290us/step - loss: 0.0845 - acc: 0.9800\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.0847 - acc: 0.9800\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 257us/step - loss: 0.0844 - acc: 0.9800\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 374us/step - loss: 0.0842 - acc: 0.9800\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.0844 - acc: 0.9800\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 312us/step - loss: 0.0841 - acc: 0.9700\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 387us/step - loss: 0.0843 - acc: 0.9800\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 288us/step - loss: 0.0842 - acc: 0.9800\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 315us/step - loss: 0.0839 - acc: 0.9800\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.0838 - acc: 0.9800\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 240us/step - loss: 0.0842 - acc: 0.9700\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 356us/step - loss: 0.0837 - acc: 0.9800\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 249us/step - loss: 0.0836 - acc: 0.9800\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 415us/step - loss: 0.0838 - acc: 0.9800\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 258us/step - loss: 0.0834 - acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18205c7a90>"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 119us/step\n",
      "50/50 [==============================] - 0s 122us/step\n"
     ]
    }
   ],
   "source": [
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 98.00%\n",
      "Test:\n",
      "acc: 94.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.12129605,  1.1414499 ,  1.8287032 ,  1.197967  , -0.23940828,\n",
       "          1.5388327 , -2.0305076 , -1.2679032 , -1.3921349 ,  1.2141073 ],\n",
       "        [-1.528534  ,  1.2004582 ,  1.132461  , -0.9021921 ,  0.12258842,\n",
       "         -1.7715137 ,  1.9272462 ,  0.7180337 , -1.5698389 ,  1.557972  ],\n",
       "        [ 0.1908095 , -2.1938727 , -1.9225051 ,  0.18214469,  0.5943558 ,\n",
       "          2.061206  ,  1.0078062 ,  0.0305413 , -0.8459417 , -1.7095819 ],\n",
       "        [-0.24911903, -1.6868356 , -0.29562044, -1.9896674 ,  0.9614039 ,\n",
       "          2.1186361 , -0.11543606, -0.45685276, -1.1881891 , -2.0133252 ]],\n",
       "       dtype=float32),\n",
       " array([-0.4369997 ,  0.83060896, -1.125353  ,  0.6968958 , -1.2465042 ,\n",
       "         0.4252797 , -0.06002772, -0.6161836 ,  0.10193942,  0.90474343],\n",
       "       dtype=float32),\n",
       " array([[-1.9974568 , -1.1079164 ,  0.74428606],\n",
       "        [ 1.3465135 , -0.78044224, -1.7003281 ],\n",
       "        [ 1.3785197 ,  0.71266013,  1.9570906 ],\n",
       "        [ 0.7566066 ,  1.8074772 , -1.8238305 ],\n",
       "        [ 0.64990187, -0.5158149 ,  0.97621155],\n",
       "        [-1.9250046 , -0.87008476,  2.367424  ],\n",
       "        [-0.05205862,  1.3140781 , -1.7909278 ],\n",
       "        [ 1.7291831 , -0.9945487 , -1.265376  ],\n",
       "        [ 0.87581617,  0.35152644, -1.0939636 ],\n",
       "        [ 1.7039464 ,  0.46797618, -1.7524608 ]], dtype=float32),\n",
       " array([-1.8978047,  1.3257744, -0.3753495], dtype=float32)]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
