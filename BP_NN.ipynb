{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width            class\n",
       "0           7.9          3.8           6.4          2.0   Iris-virginica\n",
       "1           6.3          2.8           5.1          1.5   Iris-virginica\n",
       "2           6.9          3.1           5.1          2.3   Iris-virginica\n",
       "3           5.0          3.0           1.6          0.2      Iris-setosa\n",
       "4           4.9          3.1           1.5          0.1      Iris-setosa\n",
       "5           5.2          4.1           1.5          0.1      Iris-setosa\n",
       "6           6.4          3.2           4.5          1.5  Iris-versicolor\n",
       "7           5.7          2.9           4.2          1.3  Iris-versicolor\n",
       "8           4.4          2.9           1.4          0.2      Iris-setosa\n",
       "9           5.7          3.0           4.2          1.2  Iris-versicolor"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.data', header=0)\n",
    "\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133755</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>0.194396</td>\n",
       "      <td>0.440533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.070464</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>0.252367</td>\n",
       "      <td>0.240533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.106751</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>-0.312850</td>\n",
       "      <td>-0.399467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.106751</td>\n",
       "      <td>0.078636</td>\n",
       "      <td>-0.327343</td>\n",
       "      <td>-0.399467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-0.056118</td>\n",
       "      <td>0.192273</td>\n",
       "      <td>-0.356329</td>\n",
       "      <td>-0.319467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.083122</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.295845</td>\n",
       "      <td>0.400533</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.119409</td>\n",
       "      <td>0.010455</td>\n",
       "      <td>-0.327343</td>\n",
       "      <td>-0.439467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-0.043460</td>\n",
       "      <td>-0.148636</td>\n",
       "      <td>-0.008502</td>\n",
       "      <td>-0.079467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.056118</td>\n",
       "      <td>0.192273</td>\n",
       "      <td>-0.298357</td>\n",
       "      <td>-0.319467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.108439</td>\n",
       "      <td>-0.012273</td>\n",
       "      <td>0.179903</td>\n",
       "      <td>0.200533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width  class\n",
       "2        0.133755     0.010455      0.194396     0.440533      2\n",
       "92       0.070464     0.010455      0.252367     0.240533      2\n",
       "3       -0.106751    -0.012273     -0.312850    -0.399467      0\n",
       "30      -0.106751     0.078636     -0.327343    -0.399467      0\n",
       "68      -0.056118     0.192273     -0.356329    -0.319467      0\n",
       "130      0.083122    -0.012273      0.295845     0.400533      2\n",
       "40      -0.119409     0.010455     -0.327343    -0.439467      0\n",
       "100     -0.043460    -0.148636     -0.008502    -0.079467      1\n",
       "51      -0.056118     0.192273     -0.298357    -0.319467      0\n",
       "77       0.108439    -0.012273      0.179903     0.200533      1"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data standartization\n",
    "for label in list(dataset)[:-1]:\n",
    "    dataset[label] = (dataset[label] - dataset[label].mean()) / dataset[label].abs().max()\n",
    "\n",
    "# Mapping classes to numbers.\n",
    "dataset['class'] = dataset['class'].map({'Iris-setosa':0, \n",
    "                                         'Iris-versicolor':1, \n",
    "                                         'Iris-virginica':2}).astype(int)\n",
    "\n",
    "train = dataset[:100]\n",
    "test = dataset[100:]\n",
    "\n",
    "X = train.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y = train.as_matrix(['class'])\n",
    "y = to_categorical(y)\n",
    "\n",
    "X_test = test.as_matrix(['sepal length', \n",
    "                   'sepal width', \n",
    "                   'petal length', \n",
    "                   'petal width'])\n",
    "y_test = test.as_matrix(['class'])\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing basic weights.\n",
    "\n",
    "all_weights = np.array([-0.8246426 ,  0.07884299, -0.9870016 ,  0.21673041,  1.43786387,\n",
    "       -1.1763207 ,  0.9649588 , -0.29070456, -1.40310029,  1.12698736,\n",
    "       -1.15316424, -0.07273833, -0.85323182,  1.04236439, -1.36566184,\n",
    "       -1.77789868, -0.21302519,  0.96712111, -1.41099737, -1.41736289,\n",
    "        0.75138089, -0.12192468,  0.50943821,  1.47398792,  0.74468672,\n",
    "        1.02979429,  1.03582831,  1.865793  , -0.12590837,  1.27421046,\n",
    "        0.57831566, -1.57700026, -0.15153545, -0.36917279, -0.0711466 ,\n",
    "       -1.60655529, -0.86532645, -1.34142208,  1.67639401,  1.14425186,\n",
    "        0.13635822, -0.54604735,  0.37368347,  1.1752136 ,  1.17340694,\n",
    "        0.45394401,  1.72495746,  0.06019248,  0.78769609,  1.41738099,\n",
    "        1.49946706,  0.09380754,  1.09982854,  0.44152848,  1.17330737,\n",
    "       -1.71606688, -1.57460793, -0.5713892 ,  1.73252073, -1.99220617,\n",
    "        0.63269955,  1.37965092, -1.73005789, -0.81178943,  0.84320478,\n",
    "       -0.14178177, -0.70061334, -0.49657083,  0.69051263, -0.0343669 ,\n",
    "       -0.94897046,  0.99317227, -0.08968825, -1.56062912, -0.73941844,\n",
    "        0.19075343,  1.08295268, -1.35231911, -0.67720738,  1.56432783,\n",
    "        0.03014081, -0.14527629,  0.94485933])\n",
    "\n",
    "#  Reshaping 1D input weights to 2 2D matrix and bias vectors.\n",
    "theta1 = all_weights[:40]\n",
    "bias1 = all_weights[40:50]\n",
    "theta2 = all_weights[50:80]\n",
    "bias2 = all_weights[80:]\n",
    "theta1 = theta1.reshape((10, 4))\n",
    "theta2 = theta2.reshape((3, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 4ms/step\n",
      "50/50 [==============================] - 0s 129us/step\n"
     ]
    }
   ],
   "source": [
    "model.set_weights([theta1.T, bias1, theta2.T, bias2])\n",
    "\n",
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 66.00%\n",
      "Test:\n",
      "acc: 68.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 1.3547 - acc: 0.6600\n",
      "Epoch 2/150\n",
      "100/100 [==============================] - 0s 405us/step - loss: 1.0287 - acc: 0.6600\n",
      "Epoch 3/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.7597 - acc: 0.6800\n",
      "Epoch 4/150\n",
      "100/100 [==============================] - 0s 443us/step - loss: 0.5502 - acc: 0.7300\n",
      "Epoch 5/150\n",
      "100/100 [==============================] - 0s 360us/step - loss: 0.4029 - acc: 0.7800\n",
      "Epoch 6/150\n",
      "100/100 [==============================] - 0s 296us/step - loss: 0.3043 - acc: 0.8400\n",
      "Epoch 7/150\n",
      "100/100 [==============================] - 0s 445us/step - loss: 0.2418 - acc: 0.8800\n",
      "Epoch 8/150\n",
      "100/100 [==============================] - 0s 442us/step - loss: 0.2037 - acc: 0.9200\n",
      "Epoch 9/150\n",
      "100/100 [==============================] - 0s 401us/step - loss: 0.1793 - acc: 0.9300\n",
      "Epoch 10/150\n",
      "100/100 [==============================] - 0s 408us/step - loss: 0.1634 - acc: 0.9600\n",
      "Epoch 11/150\n",
      "100/100 [==============================] - 0s 438us/step - loss: 0.1539 - acc: 0.9700\n",
      "Epoch 12/150\n",
      "100/100 [==============================] - 0s 274us/step - loss: 0.1475 - acc: 0.9600\n",
      "Epoch 13/150\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.1430 - acc: 0.9600\n",
      "Epoch 14/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.1401 - acc: 0.9600\n",
      "Epoch 15/150\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.1382 - acc: 0.9600\n",
      "Epoch 16/150\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.1362 - acc: 0.9600\n",
      "Epoch 17/150\n",
      "100/100 [==============================] - 0s 343us/step - loss: 0.1350 - acc: 0.9600\n",
      "Epoch 18/150\n",
      "100/100 [==============================] - 0s 486us/step - loss: 0.1339 - acc: 0.9700\n",
      "Epoch 19/150\n",
      "100/100 [==============================] - 0s 416us/step - loss: 0.1331 - acc: 0.9700\n",
      "Epoch 20/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1320 - acc: 0.9700\n",
      "Epoch 21/150\n",
      "100/100 [==============================] - 0s 370us/step - loss: 0.1319 - acc: 0.9700\n",
      "Epoch 22/150\n",
      "100/100 [==============================] - 0s 380us/step - loss: 0.1308 - acc: 0.9800\n",
      "Epoch 23/150\n",
      "100/100 [==============================] - 0s 465us/step - loss: 0.1306 - acc: 0.9700\n",
      "Epoch 24/150\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.1296 - acc: 0.9800\n",
      "Epoch 25/150\n",
      "100/100 [==============================] - 0s 357us/step - loss: 0.1295 - acc: 0.9700\n",
      "Epoch 26/150\n",
      "100/100 [==============================] - 0s 382us/step - loss: 0.1290 - acc: 0.9800\n",
      "Epoch 27/150\n",
      "100/100 [==============================] - 0s 323us/step - loss: 0.1281 - acc: 0.9800\n",
      "Epoch 28/150\n",
      "100/100 [==============================] - 0s 308us/step - loss: 0.1277 - acc: 0.9800\n",
      "Epoch 29/150\n",
      "100/100 [==============================] - 0s 352us/step - loss: 0.1274 - acc: 0.9800\n",
      "Epoch 30/150\n",
      "100/100 [==============================] - 0s 423us/step - loss: 0.1270 - acc: 0.9800\n",
      "Epoch 31/150\n",
      "100/100 [==============================] - 0s 420us/step - loss: 0.1267 - acc: 0.9800\n",
      "Epoch 32/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.1261 - acc: 0.9800\n",
      "Epoch 33/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1255 - acc: 0.9800\n",
      "Epoch 34/150\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.1252 - acc: 0.9800\n",
      "Epoch 35/150\n",
      "100/100 [==============================] - 0s 552us/step - loss: 0.1250 - acc: 0.9800\n",
      "Epoch 36/150\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.1243 - acc: 0.9700\n",
      "Epoch 37/150\n",
      "100/100 [==============================] - 0s 330us/step - loss: 0.1241 - acc: 0.9800\n",
      "Epoch 38/150\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.1239 - acc: 0.9700\n",
      "Epoch 39/150\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.1235 - acc: 0.9800\n",
      "Epoch 40/150\n",
      "100/100 [==============================] - 0s 764us/step - loss: 0.1232 - acc: 0.9800\n",
      "Epoch 41/150\n",
      "100/100 [==============================] - 0s 843us/step - loss: 0.1231 - acc: 0.9800\n",
      "Epoch 42/150\n",
      "100/100 [==============================] - 0s 867us/step - loss: 0.1231 - acc: 0.9800\n",
      "Epoch 43/150\n",
      "100/100 [==============================] - 0s 621us/step - loss: 0.1221 - acc: 0.9800\n",
      "Epoch 44/150\n",
      "100/100 [==============================] - 0s 372us/step - loss: 0.1218 - acc: 0.9800\n",
      "Epoch 45/150\n",
      "100/100 [==============================] - 0s 365us/step - loss: 0.1215 - acc: 0.9800\n",
      "Epoch 46/150\n",
      "100/100 [==============================] - 0s 342us/step - loss: 0.1212 - acc: 0.9800\n",
      "Epoch 47/150\n",
      "100/100 [==============================] - 0s 885us/step - loss: 0.1209 - acc: 0.9800\n",
      "Epoch 48/150\n",
      "100/100 [==============================] - 0s 568us/step - loss: 0.1205 - acc: 0.9800\n",
      "Epoch 49/150\n",
      "100/100 [==============================] - 0s 495us/step - loss: 0.1204 - acc: 0.9700\n",
      "Epoch 50/150\n",
      "100/100 [==============================] - 0s 505us/step - loss: 0.1203 - acc: 0.9800\n",
      "Epoch 51/150\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.1200 - acc: 0.9800\n",
      "Epoch 52/150\n",
      "100/100 [==============================] - 0s 328us/step - loss: 0.1198 - acc: 0.9700\n",
      "Epoch 53/150\n",
      "100/100 [==============================] - 0s 339us/step - loss: 0.1195 - acc: 0.9700\n",
      "Epoch 54/150\n",
      "100/100 [==============================] - 0s 334us/step - loss: 0.1194 - acc: 0.9800\n",
      "Epoch 55/150\n",
      "100/100 [==============================] - 0s 358us/step - loss: 0.1193 - acc: 0.9800\n",
      "Epoch 56/150\n",
      "100/100 [==============================] - 0s 452us/step - loss: 0.1189 - acc: 0.9800\n",
      "Epoch 57/150\n",
      "100/100 [==============================] - 0s 413us/step - loss: 0.1188 - acc: 0.9800\n",
      "Epoch 58/150\n",
      "100/100 [==============================] - 0s 336us/step - loss: 0.1182 - acc: 0.9800\n",
      "Epoch 59/150\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.1179 - acc: 0.9800\n",
      "Epoch 60/150\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.1176 - acc: 0.9800\n",
      "Epoch 61/150\n",
      "100/100 [==============================] - 0s 433us/step - loss: 0.1176 - acc: 0.9800\n",
      "Epoch 62/150\n",
      "100/100 [==============================] - 0s 221us/step - loss: 0.1172 - acc: 0.9800\n",
      "Epoch 63/150\n",
      "100/100 [==============================] - 0s 376us/step - loss: 0.1174 - acc: 0.9800\n",
      "Epoch 64/150\n",
      "100/100 [==============================] - 0s 337us/step - loss: 0.1167 - acc: 0.9800\n",
      "Epoch 65/150\n",
      "100/100 [==============================] - 0s 595us/step - loss: 0.1166 - acc: 0.9800\n",
      "Epoch 66/150\n",
      "100/100 [==============================] - 0s 584us/step - loss: 0.1165 - acc: 0.9800\n",
      "Epoch 67/150\n",
      "100/100 [==============================] - 0s 557us/step - loss: 0.1159 - acc: 0.9800\n",
      "Epoch 68/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.1159 - acc: 0.9800\n",
      "Epoch 69/150\n",
      "100/100 [==============================] - 0s 333us/step - loss: 0.1155 - acc: 0.9800\n",
      "Epoch 70/150\n",
      "100/100 [==============================] - 0s 385us/step - loss: 0.1154 - acc: 0.9700\n",
      "Epoch 71/150\n",
      "100/100 [==============================] - 0s 244us/step - loss: 0.1153 - acc: 0.9800\n",
      "Epoch 72/150\n",
      "100/100 [==============================] - 0s 381us/step - loss: 0.1149 - acc: 0.9800\n",
      "Epoch 73/150\n",
      "100/100 [==============================] - 0s 328us/step - loss: 0.1147 - acc: 0.9800\n",
      "Epoch 74/150\n",
      "100/100 [==============================] - 0s 323us/step - loss: 0.1144 - acc: 0.9800\n",
      "Epoch 75/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1143 - acc: 0.9800\n",
      "Epoch 76/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1141 - acc: 0.9800\n",
      "Epoch 77/150\n",
      "100/100 [==============================] - 0s 314us/step - loss: 0.1139 - acc: 0.9800\n",
      "Epoch 78/150\n",
      "100/100 [==============================] - 0s 304us/step - loss: 0.1139 - acc: 0.9800\n",
      "Epoch 79/150\n",
      "100/100 [==============================] - 0s 344us/step - loss: 0.1135 - acc: 0.9800\n",
      "Epoch 80/150\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.1135 - acc: 0.9700\n",
      "Epoch 81/150\n",
      "100/100 [==============================] - 0s 338us/step - loss: 0.1133 - acc: 0.9700\n",
      "Epoch 82/150\n",
      "100/100 [==============================] - 0s 340us/step - loss: 0.1132 - acc: 0.9700\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 332us/step - loss: 0.1127 - acc: 0.9800\n",
      "Epoch 84/150\n",
      "100/100 [==============================] - 0s 353us/step - loss: 0.1126 - acc: 0.9700\n",
      "Epoch 85/150\n",
      "100/100 [==============================] - 0s 456us/step - loss: 0.1123 - acc: 0.9800\n",
      "Epoch 86/150\n",
      "100/100 [==============================] - 0s 462us/step - loss: 0.1124 - acc: 0.9800\n",
      "Epoch 87/150\n",
      "100/100 [==============================] - 0s 234us/step - loss: 0.1123 - acc: 0.9700\n",
      "Epoch 88/150\n",
      "100/100 [==============================] - 0s 488us/step - loss: 0.1118 - acc: 0.9800\n",
      "Epoch 89/150\n",
      "100/100 [==============================] - 0s 264us/step - loss: 0.1116 - acc: 0.9800\n",
      "Epoch 90/150\n",
      "100/100 [==============================] - 0s 424us/step - loss: 0.1114 - acc: 0.9800\n",
      "Epoch 91/150\n",
      "100/100 [==============================] - 0s 286us/step - loss: 0.1113 - acc: 0.9700\n",
      "Epoch 92/150\n",
      "100/100 [==============================] - 0s 286us/step - loss: 0.1113 - acc: 0.9800\n",
      "Epoch 93/150\n",
      "100/100 [==============================] - 0s 369us/step - loss: 0.1109 - acc: 0.9800\n",
      "Epoch 94/150\n",
      "100/100 [==============================] - 0s 248us/step - loss: 0.1107 - acc: 0.9800\n",
      "Epoch 95/150\n",
      "100/100 [==============================] - 0s 393us/step - loss: 0.1107 - acc: 0.9800\n",
      "Epoch 96/150\n",
      "100/100 [==============================] - 0s 265us/step - loss: 0.1105 - acc: 0.9700\n",
      "Epoch 97/150\n",
      "100/100 [==============================] - 0s 350us/step - loss: 0.1105 - acc: 0.9700\n",
      "Epoch 98/150\n",
      "100/100 [==============================] - 0s 437us/step - loss: 0.1101 - acc: 0.9800\n",
      "Epoch 99/150\n",
      "100/100 [==============================] - 0s 260us/step - loss: 0.1098 - acc: 0.9800\n",
      "Epoch 100/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.1098 - acc: 0.9700\n",
      "Epoch 101/150\n",
      "100/100 [==============================] - 0s 395us/step - loss: 0.1099 - acc: 0.9800\n",
      "Epoch 102/150\n",
      "100/100 [==============================] - 0s 273us/step - loss: 0.1094 - acc: 0.9800\n",
      "Epoch 103/150\n",
      "100/100 [==============================] - 0s 463us/step - loss: 0.1090 - acc: 0.9800\n",
      "Epoch 104/150\n",
      "100/100 [==============================] - 0s 305us/step - loss: 0.1094 - acc: 0.9800\n",
      "Epoch 105/150\n",
      "100/100 [==============================] - 0s 482us/step - loss: 0.1091 - acc: 0.9800\n",
      "Epoch 106/150\n",
      "100/100 [==============================] - 0s 481us/step - loss: 0.1090 - acc: 0.9700\n",
      "Epoch 107/150\n",
      "100/100 [==============================] - 0s 274us/step - loss: 0.1086 - acc: 0.9700\n",
      "Epoch 108/150\n",
      "100/100 [==============================] - 0s 261us/step - loss: 0.1086 - acc: 0.9700\n",
      "Epoch 109/150\n",
      "100/100 [==============================] - 0s 436us/step - loss: 0.1087 - acc: 0.9800\n",
      "Epoch 110/150\n",
      "100/100 [==============================] - 0s 245us/step - loss: 0.1083 - acc: 0.9800\n",
      "Epoch 111/150\n",
      "100/100 [==============================] - 0s 421us/step - loss: 0.1084 - acc: 0.9700\n",
      "Epoch 112/150\n",
      "100/100 [==============================] - 0s 229us/step - loss: 0.1080 - acc: 0.9700\n",
      "Epoch 113/150\n",
      "100/100 [==============================] - 0s 390us/step - loss: 0.1080 - acc: 0.9800\n",
      "Epoch 114/150\n",
      "100/100 [==============================] - 0s 221us/step - loss: 0.1076 - acc: 0.9800\n",
      "Epoch 115/150\n",
      "100/100 [==============================] - 0s 351us/step - loss: 0.1070 - acc: 0.9700\n",
      "Epoch 116/150\n",
      "100/100 [==============================] - 0s 348us/step - loss: 0.1073 - acc: 0.9700\n",
      "Epoch 117/150\n",
      "100/100 [==============================] - 0s 283us/step - loss: 0.1075 - acc: 0.9700\n",
      "Epoch 118/150\n",
      "100/100 [==============================] - 0s 459us/step - loss: 0.1071 - acc: 0.9800\n",
      "Epoch 119/150\n",
      "100/100 [==============================] - 0s 252us/step - loss: 0.1066 - acc: 0.9700\n",
      "Epoch 120/150\n",
      "100/100 [==============================] - 0s 476us/step - loss: 0.1069 - acc: 0.9700\n",
      "Epoch 121/150\n",
      "100/100 [==============================] - 0s 311us/step - loss: 0.1063 - acc: 0.9700\n",
      "Epoch 122/150\n",
      "100/100 [==============================] - 0s 496us/step - loss: 0.1068 - acc: 0.9700\n",
      "Epoch 123/150\n",
      "100/100 [==============================] - 0s 283us/step - loss: 0.1060 - acc: 0.9700\n",
      "Epoch 124/150\n",
      "100/100 [==============================] - 0s 465us/step - loss: 0.1060 - acc: 0.9800\n",
      "Epoch 125/150\n",
      "100/100 [==============================] - 0s 332us/step - loss: 0.1056 - acc: 0.9700\n",
      "Epoch 126/150\n",
      "100/100 [==============================] - 0s 303us/step - loss: 0.1059 - acc: 0.9700\n",
      "Epoch 127/150\n",
      "100/100 [==============================] - 0s 502us/step - loss: 0.1053 - acc: 0.9700\n",
      "Epoch 128/150\n",
      "100/100 [==============================] - 0s 327us/step - loss: 0.1052 - acc: 0.9800\n",
      "Epoch 129/150\n",
      "100/100 [==============================] - 0s 475us/step - loss: 0.1052 - acc: 0.9700\n",
      "Epoch 130/150\n",
      "100/100 [==============================] - 0s 297us/step - loss: 0.1056 - acc: 0.9700\n",
      "Epoch 131/150\n",
      "100/100 [==============================] - 0s 478us/step - loss: 0.1052 - acc: 0.9700\n",
      "Epoch 132/150\n",
      "100/100 [==============================] - 0s 255us/step - loss: 0.1049 - acc: 0.9800\n",
      "Epoch 133/150\n",
      "100/100 [==============================] - 0s 501us/step - loss: 0.1049 - acc: 0.9800\n",
      "Epoch 134/150\n",
      "100/100 [==============================] - 0s 298us/step - loss: 0.1044 - acc: 0.9700\n",
      "Epoch 135/150\n",
      "100/100 [==============================] - 0s 494us/step - loss: 0.1042 - acc: 0.9800\n",
      "Epoch 136/150\n",
      "100/100 [==============================] - 0s 326us/step - loss: 0.1041 - acc: 0.9700\n",
      "Epoch 137/150\n",
      "100/100 [==============================] - 0s 417us/step - loss: 0.1039 - acc: 0.9700\n",
      "Epoch 138/150\n",
      "100/100 [==============================] - 0s 262us/step - loss: 0.1038 - acc: 0.9800\n",
      "Epoch 139/150\n",
      "100/100 [==============================] - 0s 289us/step - loss: 0.1039 - acc: 0.9800\n",
      "Epoch 140/150\n",
      "100/100 [==============================] - 0s 497us/step - loss: 0.1036 - acc: 0.9700\n",
      "Epoch 141/150\n",
      "100/100 [==============================] - 0s 311us/step - loss: 0.1034 - acc: 0.9800\n",
      "Epoch 142/150\n",
      "100/100 [==============================] - 0s 422us/step - loss: 0.1034 - acc: 0.9700\n",
      "Epoch 143/150\n",
      "100/100 [==============================] - 0s 293us/step - loss: 0.1033 - acc: 0.9700\n",
      "Epoch 144/150\n",
      "100/100 [==============================] - 0s 406us/step - loss: 0.1032 - acc: 0.9700\n",
      "Epoch 145/150\n",
      "100/100 [==============================] - 0s 341us/step - loss: 0.1028 - acc: 0.9700\n",
      "Epoch 146/150\n",
      "100/100 [==============================] - 0s 293us/step - loss: 0.1031 - acc: 0.9700\n",
      "Epoch 147/150\n",
      "100/100 [==============================] - 0s 354us/step - loss: 0.1028 - acc: 0.9700\n",
      "Epoch 148/150\n",
      "100/100 [==============================] - 0s 368us/step - loss: 0.1025 - acc: 0.9700\n",
      "Epoch 149/150\n",
      "100/100 [==============================] - 0s 306us/step - loss: 0.1028 - acc: 0.9800\n",
      "Epoch 150/150\n",
      "100/100 [==============================] - 0s 313us/step - loss: 0.1022 - acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1820f6df10>"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 0s 133us/step\n",
      "50/50 [==============================] - 0s 156us/step\n"
     ]
    }
   ],
   "source": [
    "scores_train = model.evaluate(X, y)\n",
    "scores_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "acc: 97.00%\n",
      "Test:\n",
      "acc: 94.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_train[1]*100))\n",
    "print(\"Test:\\n%s: %.2f%%\" % (model.metrics_names[1], scores_test[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 10)                50        \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.12129605,  1.1414499 ,  1.8287032 ,  1.197967  , -0.23940828,\n",
       "          1.5388327 , -2.0305076 , -1.2679032 , -1.3921349 ,  1.2141073 ],\n",
       "        [-1.528534  ,  1.2004582 ,  1.132461  , -0.9021921 ,  0.12258842,\n",
       "         -1.7715137 ,  1.9272462 ,  0.7180337 , -1.5698389 ,  1.557972  ],\n",
       "        [ 0.1908095 , -2.1938727 , -1.9225051 ,  0.18214469,  0.5943558 ,\n",
       "          2.061206  ,  1.0078062 ,  0.0305413 , -0.8459417 , -1.7095819 ],\n",
       "        [-0.24911903, -1.6868356 , -0.29562044, -1.9896674 ,  0.9614039 ,\n",
       "          2.1186361 , -0.11543606, -0.45685276, -1.1881891 , -2.0133252 ]],\n",
       "       dtype=float32),\n",
       " array([-0.4369997 ,  0.83060896, -1.125353  ,  0.6968958 , -1.2465042 ,\n",
       "         0.4252797 , -0.06002772, -0.6161836 ,  0.10193942,  0.90474343],\n",
       "       dtype=float32),\n",
       " array([[-1.9974568 , -1.1079164 ,  0.74428606],\n",
       "        [ 1.3465135 , -0.78044224, -1.7003281 ],\n",
       "        [ 1.3785197 ,  0.71266013,  1.9570906 ],\n",
       "        [ 0.7566066 ,  1.8074772 , -1.8238305 ],\n",
       "        [ 0.64990187, -0.5158149 ,  0.97621155],\n",
       "        [-1.9250046 , -0.87008476,  2.367424  ],\n",
       "        [-0.05205862,  1.3140781 , -1.7909278 ],\n",
       "        [ 1.7291831 , -0.9945487 , -1.265376  ],\n",
       "        [ 0.87581617,  0.35152644, -1.0939636 ],\n",
       "        [ 1.7039464 ,  0.46797618, -1.7524608 ]], dtype=float32),\n",
       " array([-1.8978047,  1.3257744, -0.3753495], dtype=float32)]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
